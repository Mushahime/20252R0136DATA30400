{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c612f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from utils import * \n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e78316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noamc\\AppData\\Roaming\\Python\\Python312\\site-packages\n"
     ]
    }
   ],
   "source": [
    "import site, sys\n",
    "sys.path.append(site.USER_SITE)\n",
    "print(site.USER_SITE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbc640c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "12.4\n",
      "True\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "542c00d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 29487 samples\n",
      "Test: 19658 samples\n",
      "Classes: 531\n",
      "Silver labels loaded\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "# Default paths\n",
    "ROOT = Path(\"Amazon_products\") # Root Amazon_products directory\n",
    "TRAIN_DIR = ROOT / \"train\"\n",
    "TEST_DIR = ROOT / \"test\"\n",
    "\n",
    "TEST_CORPUS_PATH = os.path.join(TEST_DIR, \"test_corpus.txt\")  # product_id \\t text\n",
    "TRAIN_CORPUS_PATH = os.path.join(TRAIN_DIR, \"train_corpus.txt\")\n",
    "\n",
    "CLASS_HIERARCHY_PATH = ROOT / \"class_hierarchy.txt\" \n",
    "CLASS_RELATED_PATH = ROOT / \"class_related_keywords.txt\" \n",
    "CLASS_PATH = ROOT / \"classes.txt\" \n",
    "\n",
    "SUBMISSION_PATH = \"Submission/submission.csv\"  # output file\n",
    "\n",
    "# --- Constants ---\n",
    "NUM_CLASSES = 531  # total number of classes (0–530)\n",
    "MIN_LABELS = 1     # minimum number of labels per sample\n",
    "MAX_LABELS = 3     # maximum number of labels per sample\n",
    "\n",
    "# Load corpus\n",
    "def load_corpus(path):\n",
    "    \"\"\"Load test corpus into {id: text} dictionary.\"\"\"\n",
    "    id2text = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\", 1)\n",
    "            if len(parts) == 2:\n",
    "                id, text = parts\n",
    "                id2text[id] = text\n",
    "    return id2text\n",
    "\n",
    "def load_multilabel(path):\n",
    "    \"\"\"Load multi-label data into {id: [labels]} dictionary.\"\"\"\n",
    "    id2labels = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) == 2:\n",
    "                pid, label = parts\n",
    "                pid = int(pid)\n",
    "                label = int(label)\n",
    "\n",
    "                if pid not in id2labels:\n",
    "                    id2labels[pid] = []\n",
    "\n",
    "                id2labels[pid].append(label)\n",
    "    return id2labels\n",
    "\n",
    "def load_class_keywords(path):\n",
    "    \"\"\"Load class keywords into {class_name: [keywords]} dictionary.\"\"\"\n",
    "    class2keywords = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if \":\" not in line:\n",
    "                continue\n",
    "            classname, keywords = line.strip().split(\":\", 1)\n",
    "            keyword_list = [kw.strip() for kw in keywords.split(\",\") if kw.strip()]\n",
    "            class2keywords[classname] = keyword_list\n",
    "    return class2keywords\n",
    "\n",
    "id2text_test = load_corpus(TEST_CORPUS_PATH)\n",
    "id_list_test = list(id2text_test.keys())\n",
    "\n",
    "id2text_train = load_corpus(TRAIN_CORPUS_PATH)\n",
    "id_list_train = list(id2text_train.keys())\n",
    "\n",
    "id2class = load_corpus(CLASS_PATH)\n",
    "class2hierarchy = load_multilabel(CLASS_HIERARCHY_PATH)\n",
    "class2related = load_class_keywords(CLASS_RELATED_PATH)\n",
    "\n",
    "# Load silver labels\n",
    "with open(\"Silver/silver_train_roberta.json\", \"r\") as f:\n",
    "    pid2labelids_silver = json.load(f)\n",
    "\n",
    "with open(\"Silver/silver_test_roberta.json\", \"r\") as f:\n",
    "    pid2labelids_test = json.load(f)\n",
    "\n",
    "print(f\"Train: {len(id2text_train)} samples\")\n",
    "print(f\"Test: {len(id2text_test)} samples\")\n",
    "print(f\"Classes: {len(id2class)}\")\n",
    "print(f\"Silver labels loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d4539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch, numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"distilroberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "model.eval()\n",
    "\n",
    "def get_embeddings(texts, batch_size=16):\n",
    "    embs = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            emb = outputs.last_hidden_state.mean(dim=1)\n",
    "        embs.append(emb.cpu().numpy())\n",
    "    return np.vstack(embs)\n",
    "\n",
    "# Embeddings pour train et test\n",
    "train_ids = list(id2text_train.keys())\n",
    "X_train = get_embeddings([id2text_train[i] for i in train_ids])\n",
    "\n",
    "test_ids = list(id2text_test.keys())\n",
    "X_test = get_embeddings([id2text_test[i] for i in test_ids])\n",
    "\n",
    "# Silver labels en vecteurs binaires\n",
    "NUM_CLASSES = 531\n",
    "y_train = np.zeros((len(train_ids), NUM_CLASSES))\n",
    "for idx, pid in enumerate(train_ids):\n",
    "    for label in pid2labelids_silver.get(str(pid), []):\n",
    "        y_train[idx, int(label)] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c59514ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33mEmbeddings\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m X_train_tensor = torch.from_numpy(\u001b[43mX_train\u001b[49m).float()\n\u001b[32m      6\u001b[39m X_test_tensor = torch.from_numpy(X_test).float()\n\u001b[32m      7\u001b[39m y_train_tensor = torch.from_numpy(y_train).float()\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import torch, os\n",
    "\n",
    "os.makedirs(\"Embeddings\", exist_ok=True)\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "torch.save(X_train_tensor, \"Embeddings/X_train.pt\")\n",
    "torch.save(X_test_tensor, \"Embeddings/X_test.pt\")\n",
    "torch.save(y_train_tensor, \"Embeddings/y_train.pt\")\n",
    "\n",
    "torch.save(train_ids, \"Embeddings/train_ids.pt\")\n",
    "torch.save(test_ids, \"Embeddings/test_ids.pt\")\n",
    "\n",
    "print(X_train_tensor.shape, y_train_tensor.shape, X_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b8ccc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de classes: 531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 49.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label embeddings saved: torch.Size([531, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch, numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Embeddings for label\n",
    "\n",
    "label_texts = [id2class[str(i)] for i in range(len(id2class))]\n",
    "print(f\"Nombre de classes: {len(label_texts)}\")\n",
    "\n",
    "label_embs = get_embeddings(label_texts)\n",
    "label_embs_tensor = torch.from_numpy(label_embs).float()\n",
    "\n",
    "# === Save ===\n",
    "torch.save(label_embs_tensor, \"Embeddings/label_emb.pt\")\n",
    "print(\"label embeddings saved:\", label_embs_tensor.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
