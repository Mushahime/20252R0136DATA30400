{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c612f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from utils import * \n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e78316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noamc\\AppData\\Roaming\\Python\\Python312\\site-packages\n"
     ]
    }
   ],
   "source": [
    "import site, sys\n",
    "sys.path.append(site.USER_SITE)\n",
    "print(site.USER_SITE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbc640c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "12.4\n",
      "True\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c00d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 29487 samples\n",
      "Test: 19658 samples\n",
      "Classes: 531\n",
      "Silver labels loaded\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "# Default paths\n",
    "ROOT = Path(\"Amazon_products\") # Root Amazon_products directory\n",
    "TRAIN_DIR = ROOT / \"train\"\n",
    "TEST_DIR = ROOT / \"test\"\n",
    "\n",
    "TEST_CORPUS_PATH = os.path.join(TEST_DIR, \"test_corpus.txt\")  # product_id \\t text\n",
    "TRAIN_CORPUS_PATH = os.path.join(TRAIN_DIR, \"train_corpus.txt\")\n",
    "\n",
    "CLASS_HIERARCHY_PATH = ROOT / \"class_hierarchy.txt\" \n",
    "CLASS_RELATED_PATH = ROOT / \"class_related_keywords.txt\" \n",
    "CLASS_PATH = ROOT / \"classes.txt\" \n",
    "\n",
    "SUBMISSION_PATH = \"Submission/submission.csv\"  # output file\n",
    "\n",
    "# --- Constants ---\n",
    "NUM_CLASSES = 531  # total number of classes (0–530)\n",
    "MIN_LABELS = 2     # minimum number of labels per sample\n",
    "MAX_LABELS = 3     # maximum number of labels per sample\n",
    "\n",
    "# Load corpus\n",
    "def load_corpus(path):\n",
    "    \"\"\"Load test corpus into {id: text} dictionary.\"\"\"\n",
    "    id2text = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\", 1)\n",
    "            if len(parts) == 2:\n",
    "                id, text = parts\n",
    "                id2text[id] = text\n",
    "    return id2text\n",
    "\n",
    "def load_multilabel(path):\n",
    "    \"\"\"Load multi-label data into {id: [labels]} dictionary.\"\"\"\n",
    "    id2labels = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) == 2:\n",
    "                pid, label = parts\n",
    "                pid = int(pid)\n",
    "                label = int(label)\n",
    "\n",
    "                if pid not in id2labels:\n",
    "                    id2labels[pid] = []\n",
    "\n",
    "                id2labels[pid].append(label)\n",
    "    return id2labels\n",
    "\n",
    "def load_class_keywords(path):\n",
    "    \"\"\"Load class keywords into {class_name: [keywords]} dictionary.\"\"\"\n",
    "    class2keywords = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if \":\" not in line:\n",
    "                continue\n",
    "            classname, keywords = line.strip().split(\":\", 1)\n",
    "            keyword_list = [kw.strip() for kw in keywords.split(\",\") if kw.strip()]\n",
    "            class2keywords[classname] = keyword_list\n",
    "    return class2keywords\n",
    "\n",
    "id2text_test = load_corpus(TEST_CORPUS_PATH)\n",
    "id_list_test = list(id2text_test.keys())\n",
    "\n",
    "id2text_train = load_corpus(TRAIN_CORPUS_PATH)\n",
    "id_list_train = list(id2text_train.keys())\n",
    "\n",
    "id2class = load_corpus(CLASS_PATH)\n",
    "class2hierarchy = load_multilabel(CLASS_HIERARCHY_PATH)\n",
    "class2related = load_class_keywords(CLASS_RELATED_PATH)\n",
    "\n",
    "print(f\"Train: {len(id2text_train)} samples\")\n",
    "print(f\"Test: {len(id2text_test)} samples\")\n",
    "print(f\"Classes: {len(id2class)}\")\n",
    "print(f\"Silver labels loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1d4539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 1843/1843 [15:50<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (29487, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 34/34 [00:00<00:00, 38.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved:\n",
      "Embeddings/X_train.pt\n",
      "Embeddings/label_emb.pt (hierarchy-aware)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch, numpy as np, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "model.eval()\n",
    "\n",
    "def get_embeddings(texts, batch_size=16):\n",
    "    embs = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Encoding\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            emb = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "        embs.append(emb.cpu().numpy())\n",
    "    return np.vstack(embs)\n",
    "\n",
    "# --- Compute product embeddings ---\n",
    "train_ids = list(id2text_train.keys())\n",
    "train_texts = [id2text_train[i] for i in train_ids]\n",
    "X_train = get_embeddings(train_texts)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "\n",
    "# --- Compute class embeddings (fix here) ---\n",
    "label_texts = [id2class[str(i)] for i in range(len(id2class))]\n",
    "label_embs = get_embeddings(label_texts)\n",
    "label_embs = torch.tensor(label_embs)\n",
    "\n",
    "# --- Propagate hierarchy info ---\n",
    "def propagate_hierarchy_to_embeddings(label_emb, hierarchy, alpha=0.20):\n",
    "    enhanced = label_emb.clone()\n",
    "    for parent, children in hierarchy.items():\n",
    "        if len(children) > 0:\n",
    "            child_embs = label_emb[children]\n",
    "            enhanced[parent] = (1 - alpha) * label_emb[parent] + alpha * child_embs.mean(0)\n",
    "    return enhanced\n",
    "\n",
    "label_embs_enriched = propagate_hierarchy_to_embeddings(label_embs, class2hierarchy, alpha=0.20)\n",
    "\n",
    "# --- Save everything ---\n",
    "os.makedirs(\"Embeddings\", exist_ok=True)\n",
    "\n",
    "torch.save(torch.from_numpy(X_train).float(), \"Embeddings/X_train.pt\")\n",
    "torch.save(label_embs_enriched.float(), \"Embeddings/label_emb.pt\")\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\"Embeddings/X_train.pt\")\n",
    "print(\"Embeddings/label_emb.pt (hierarchy-aware)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
