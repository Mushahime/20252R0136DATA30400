{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8cfbf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Device: cuda\n",
      "Train IDs: 29487 | Test IDs: 19658\n",
      "\n",
      "ðŸ§  Loading X_all.pt ...\n",
      "âœ“ X_train: torch.Size([29487, 768]), X_test: torch.Size([19658, 768])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIGURATION\n",
    "# ==========================================================\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ðŸ”§ Device: {device}\")\n",
    "\n",
    "# Paths\n",
    "ROOT = Path(\"Amazon_products\")\n",
    "TRAIN_CORPUS_PATH = ROOT / \"train\" / \"train_corpus.txt\"\n",
    "TEST_CORPUS_PATH  = ROOT / \"test\" / \"test_corpus.txt\"\n",
    "CLASS_PATH        = ROOT / \"classes.txt\"\n",
    "\n",
    "EMB_DIR      = Path(\"Embeddings\")\n",
    "X_ALL_PATH   = EMB_DIR / \"X_train_test.pt\"        # Train + Test embeddings\n",
    "LABEL_EMB_PATH = EMB_DIR / \"labels_hierarchical.pt\"\n",
    "\n",
    "MODEL_SAVE = Path(\"Models\")\n",
    "MODEL_SAVE.mkdir(exist_ok=True)\n",
    "MODEL_PATH = MODEL_SAVE / \"silver_classifier.pt\"\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD IDS\n",
    "# ==========================================================\n",
    "def load_ids(path):\n",
    "    ids = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            pid, _ = line.strip().split(\"\\t\", 1)\n",
    "            ids.append(int(pid))\n",
    "    return ids\n",
    "\n",
    "train_ids = load_ids(TRAIN_CORPUS_PATH)\n",
    "test_ids  = load_ids(TEST_CORPUS_PATH)\n",
    "n_train = len(train_ids)\n",
    "n_test = len(test_ids)\n",
    "\n",
    "print(f\"Train IDs: {n_train} | Test IDs: {n_test}\")\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD SILVER LABELS\n",
    "# ==========================================================\n",
    "with open(\"Silver/silver_train_modify.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "silver_labels = {int(pid): data[\"labels\"] for pid, data in raw.items()}\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD X_all â†’ split into X_train + X_test\n",
    "# ==========================================================\n",
    "print(\"\\nðŸ§  Loading X_all.pt ...\")\n",
    "\n",
    "data = torch.load(X_ALL_PATH, weights_only=False)\n",
    "\n",
    "# ensure tensor\n",
    "if isinstance(data, np.ndarray):\n",
    "    data = torch.from_numpy(data)\n",
    "elif isinstance(data, list):\n",
    "    data = torch.stack(data)\n",
    "\n",
    "X_all = data.float().to(device)\n",
    "assert X_all.shape[0] == n_train + n_test, \"Bad size\"\n",
    "\n",
    "X_train = X_all[:n_train]\n",
    "X_test  = X_all[n_train:]\n",
    "print(f\"âœ“ X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD CLASS NAMES\n",
    "# ==========================================================\n",
    "classes = {}\n",
    "with open(CLASS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        cid, cname = line.strip().split(\"\\t\")\n",
    "        classes[int(cid)] = cname\n",
    "\n",
    "n_classes = len(classes)\n",
    "\n",
    "pid2idx = {pid: i for i, pid in enumerate(train_ids)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d97c569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, pids, labels_dict):\n",
    "        self.pids = pids\n",
    "        self.labels = labels_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pid = self.pids[idx]\n",
    "        emb = X_train[pid2idx[pid]]\n",
    "\n",
    "        y = torch.zeros(n_classes)\n",
    "        for c in self.labels[pid]:\n",
    "            if 0 <= c < n_classes:\n",
    "                y[c] = 1.0\n",
    "\n",
    "        return {\"X\": emb, \"y\": y}\n",
    "\n",
    "# TRAIN / VAL splits\n",
    "train_p, val_p = train_test_split(list(silver_labels.keys()),\n",
    "                                  test_size=0.2,\n",
    "                                  random_state=42)\n",
    "\n",
    "train_dataset = MultiLabelDataset(train_p, silver_labels)\n",
    "val_dataset   = MultiLabelDataset(val_p,   silver_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f453b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(512, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.drop(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "model = Classifier(X_train.size(1), n_classes).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c66208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, thr=0.25):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            X = batch[\"X\"]\n",
    "            y = batch[\"y\"].numpy()\n",
    "\n",
    "            prob = torch.sigmoid(model(X)).cpu().numpy()\n",
    "            pred = (prob > thr).astype(int)\n",
    "\n",
    "            preds.extend(pred)\n",
    "            labels.extend(y)\n",
    "\n",
    "    f1s = f1_score(labels, preds, average=\"samples\")\n",
    "    f1m = f1_score(labels, preds, average=\"macro\")\n",
    "    return f1s, f1m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dca9836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 124.24it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss=0.0429 | F1=0.7086\n",
      "ðŸ”¥ New best model saved (0.7086)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 125.29it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] loss=0.0092 | F1=0.7507\n",
      "ðŸ”¥ New best model saved (0.7507)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 129.48it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] loss=0.0075 | F1=0.7660\n",
      "ðŸ”¥ New best model saved (0.7660)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 135.93it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] loss=0.0068 | F1=0.7760\n",
      "ðŸ”¥ New best model saved (0.7760)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 133.58it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] loss=0.0062 | F1=0.7816\n",
      "ðŸ”¥ New best model saved (0.7816)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 132.72it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] loss=0.0059 | F1=0.7837\n",
      "ðŸ”¥ New best model saved (0.7837)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 133.49it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] loss=0.0056 | F1=0.7902\n",
      "ðŸ”¥ New best model saved (0.7902)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 130.45it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] loss=0.0054 | F1=0.7901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 134.59it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] loss=0.0052 | F1=0.7913\n",
      "ðŸ”¥ New best model saved (0.7913)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 129.30it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] loss=0.0050 | F1=0.7921\n",
      "ðŸ”¥ New best model saved (0.7921)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 134.87it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] loss=0.0048 | F1=0.7944\n",
      "ðŸ”¥ New best model saved (0.7944)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 126.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] loss=0.0047 | F1=0.7950\n",
      "ðŸ”¥ New best model saved (0.7950)\n",
      "\n",
      "ðŸŽ‰ Best validation F1 = 0.7950\n",
      "ðŸ“¦ Model saved at: Models\\silver_classifier.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸš€ Training...\")\n",
    "best = 0\n",
    "epochs = 12\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    total = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        X = batch[\"X\"]\n",
    "        y = batch[\"y\"].to(device)\n",
    "\n",
    "        logits = model(X)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += loss.item()\n",
    "\n",
    "    f1s, f1m = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"[Epoch {epoch}] loss={total/len(train_loader):.4f} | F1={f1s:.4f}\")\n",
    "\n",
    "    if f1s > best:\n",
    "        best = f1s\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        print(f\"ðŸ”¥ New best model saved ({best:.4f})\")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Best validation F1 = {best:.4f}\")\n",
    "print(f\"ðŸ“¦ Model saved at: {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31708868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test IDs: 19658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [00:02<00:00, 145.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Submission saved â†’ Submission\\submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "MODEL_PATH = Path(\"Models\") / \"silver_classifier.pt\"\n",
    "OUT_DIR    = Path(\"Submission\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "OUT_PATH   = OUT_DIR / \"submission.csv\"\n",
    "\n",
    "test_ids = []\n",
    "with open(TEST_CORPUS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        pid, _ = line.strip().split(\"\\t\", 1)\n",
    "        test_ids.append(int(pid))\n",
    "\n",
    "print(f\"Loaded test IDs: {len(test_ids)}\")\n",
    "\n",
    "X_all = torch.load(X_ALL_PATH, weights_only=False)\n",
    "if isinstance(X_all, np.ndarray):\n",
    "    X_all = torch.from_numpy(X_all)\n",
    "elif isinstance(X_all, list):\n",
    "    X_all = torch.stack(X_all)\n",
    "\n",
    "X_all = X_all.float()\n",
    "\n",
    "n_test = len(test_ids)\n",
    "X_test = X_all[-n_test:]\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "# ==========================================================\n",
    "# PREDICTION\n",
    "# ==========================================================\n",
    "THR = 0.5\n",
    "MIN_L = 2\n",
    "MAX_L = 3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "X_test = X_test.to(device)\n",
    "\n",
    "preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for start in tqdm(range(0, len(X_test), 64)):\n",
    "        batch = X_test[start:start+64]\n",
    "        probs = torch.sigmoid(model(batch)).cpu().numpy()\n",
    "\n",
    "        for p in probs:\n",
    "            pred = (p > THR).astype(int)\n",
    "\n",
    "            # Post-processing\n",
    "            if pred.sum() == 0:\n",
    "                pred[np.argsort(p)[-MIN_L:]] = 1\n",
    "            elif pred.sum() == 1:\n",
    "                pred[np.argsort(p)[-2:]] = 1\n",
    "            elif pred.sum() > MAX_L:\n",
    "                pred = np.zeros_like(pred)\n",
    "                pred[np.argsort(p)[-MAX_L:]] = 1\n",
    "\n",
    "            labels = [str(i) for i, v in enumerate(pred) if v == 1]\n",
    "            preds.append(labels)\n",
    "\n",
    "# ==========================================================\n",
    "# SAVE CSV\n",
    "# ==========================================================\n",
    "with open(OUT_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"id\", \"label\"])\n",
    "    for pid, labels in zip(test_ids, preds):\n",
    "        w.writerow([pid, \",\".join(labels)])\n",
    "\n",
    "print(f\"ðŸŽ‰ Submission saved â†’ {OUT_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
