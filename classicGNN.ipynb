{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f1de972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Device: cuda\n",
      "Train IDs: 29487 | Test IDs: 19658\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from utils import *\n",
    "\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIGURATION\n",
    "# ==========================================================\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ðŸ”§ Device: {device}\")\n",
    "\n",
    "# Paths\n",
    "ROOT = Path(\"Amazon_products\")\n",
    "TRAIN_CORPUS_PATH = ROOT / \"train\" / \"train_corpus.txt\"\n",
    "TEST_CORPUS_PATH  = ROOT / \"test\" / \"test_corpus.txt\"\n",
    "CLASS_PATH        = ROOT / \"classes.txt\"\n",
    "\n",
    "EMB_DIR          = Path(\"Embeddings\")\n",
    "X_ALL_PATH       = EMB_DIR / \"X_train_test_mpn.pt\"\n",
    "LABEL_EMB_PATH   = EMB_DIR / \"labels_hierarchical_new_mpn.pt\"\n",
    "\n",
    "MODEL_SAVE = Path(\"Models\")\n",
    "MODEL_SAVE.mkdir(exist_ok=True)\n",
    "MODEL_PATH = MODEL_SAVE / \"silver_classifier.pt\"\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD IDS\n",
    "# ==========================================================\n",
    "def load_ids(path):\n",
    "    ids = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            pid, _ = line.strip().split(\"\\t\", 1)\n",
    "            ids.append(int(pid))\n",
    "    return ids\n",
    "\n",
    "train_ids = load_ids(TRAIN_CORPUS_PATH)\n",
    "test_ids  = load_ids(TEST_CORPUS_PATH)\n",
    "n_train = len(train_ids)\n",
    "n_test  = len(test_ids)\n",
    "\n",
    "print(f\"Train IDs: {n_train} | Test IDs: {n_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be205a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§  Loading X_all.pt ...\n",
      "âœ“ X_train: torch.Size([29487, 768]) | X_test: torch.Size([19658, 768])\n",
      "âœ“ Label embeddings: torch.Size([531, 768])\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# LOAD SILVER LABELS\n",
    "# ==========================================================\n",
    "with open(\"Silver/silver_train_new_mpn.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "silver_labels = {int(pid): data[\"labels\"] for pid, data in raw.items()}\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD X_all\n",
    "# ==========================================================\n",
    "print(\"\\nðŸ§  Loading X_all.pt ...\")\n",
    "data = torch.load(X_ALL_PATH, weights_only=False)\n",
    "\n",
    "if isinstance(data, np.ndarray):\n",
    "    data = torch.from_numpy(data)\n",
    "elif isinstance(data, list):\n",
    "    data = torch.stack(data)\n",
    "\n",
    "X_all = data.float().to(device)\n",
    "assert X_all.shape[0] == n_train + n_test\n",
    "\n",
    "X_train = X_all[:n_train]\n",
    "X_test  = X_all[n_train:]\n",
    "print(f\"âœ“ X_train: {X_train.shape} | X_test: {X_test.shape}\")\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD LABEL EMBEDDINGS\n",
    "# ==========================================================\n",
    "tmp = torch.load(LABEL_EMB_PATH, weights_only=False)\n",
    "\n",
    "# Convertir numpy â†’ tensor si nÃ©cessaire\n",
    "if isinstance(tmp, np.ndarray):\n",
    "    tmp = torch.from_numpy(tmp)\n",
    "\n",
    "label_emb = tmp.float().to(device)\n",
    "print(f\"âœ“ Label embeddings: {label_emb.shape}\")\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD CLASS NAMES\n",
    "# ==========================================================\n",
    "classes = {}\n",
    "with open(CLASS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        cid, cname = line.strip().split(\"\\t\")\n",
    "        classes[int(cid)] = cname\n",
    "\n",
    "n_classes = len(classes)\n",
    "\n",
    "pid2idx = {pid: i for i, pid in enumerate(train_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935f05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, pids, labels_dict):\n",
    "        self.pids = pids\n",
    "        self.labels = labels_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pid = self.pids[idx]\n",
    "        emb = X_train[pid2idx[pid]]\n",
    "\n",
    "        y = torch.zeros(n_classes)\n",
    "        for c in self.labels[pid]:\n",
    "            if 0 <= c < n_classes:\n",
    "                y[c] = 1.0\n",
    "\n",
    "        return {\"X\": emb, \"y\": y}\n",
    "\n",
    "train_p, val_p = train_test_split(\n",
    "    list(silver_labels.keys()), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = MultiLabelDataset(train_p, silver_labels)\n",
    "val_dataset   = MultiLabelDataset(val_p, silver_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=64)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bcc166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, thr=0.25):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            X = batch[\"X\"]\n",
    "            y = batch[\"y\"].numpy()\n",
    "\n",
    "            prob = torch.sigmoid(model(X)).cpu().numpy()\n",
    "            pred = (prob > thr).astype(int)\n",
    "\n",
    "            preds.extend(pred)\n",
    "            labels.extend(y)\n",
    "\n",
    "    f1s = f1_score(labels, preds, average=\"samples\")\n",
    "    f1m = f1_score(labels, preds, average=\"macro\")\n",
    "    return f1s, f1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35ffe63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelGCN(nn.Module):\n",
    "    def __init__(self, emb_dim, num_layers=1, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.W_list = nn.ParameterList()\n",
    "        for _ in range(num_layers):\n",
    "            W = nn.Parameter(torch.empty(emb_dim, emb_dim))\n",
    "            nn.init.xavier_uniform_(W)\n",
    "            self.W_list.append(W)\n",
    "\n",
    "    def forward(self, H, A_hat):\n",
    "        for i, W in enumerate(self.W_list):\n",
    "            H_input = H  # skip connection\n",
    "\n",
    "            H_msg = A_hat @ H_input\n",
    "            H_msg = H_msg @ W\n",
    "\n",
    "            # residual connection\n",
    "            H = H_input + H_msg\n",
    "\n",
    "            if i < self.num_layers - 1:\n",
    "                H = F.relu(H)\n",
    "                H = F.dropout(H, p=self.dropout, training=self.training)\n",
    "\n",
    "        return H\n",
    "\n",
    "\n",
    "class GCNEnhancedClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, label_init_emb, A_hat, num_layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        emb_dim = label_init_emb.size(1)\n",
    "\n",
    "        # proj docs -> label space\n",
    "        self.proj = nn.Linear(input_dim, emb_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # GNN sur les labels\n",
    "        self.encoder = LabelGCN(emb_dim, num_layers=num_layers, dropout=dropout)\n",
    "\n",
    "        # label embeddings trainables\n",
    "        self.label_emb = nn.Parameter(label_init_emb.clone())\n",
    "\n",
    "        # matrice dâ€™adjacence (buffer, pas un paramÃ¨tre)\n",
    "        self.register_buffer(\"A_hat\", A_hat)\n",
    "\n",
    "    def forward(self, x, use_dropout=True):\n",
    "        # 1) raffiner les embeddings de labels\n",
    "        E_refine = self.encoder(self.label_emb, self.A_hat)   # (C, D)\n",
    "\n",
    "        # 2) projeter les docs\n",
    "        x_proj = self.proj(x)\n",
    "        if use_dropout:\n",
    "            x_proj = F.dropout(x_proj, p=self.dropout, training=self.training)\n",
    "\n",
    "        # 3) logits = produit scalaire\n",
    "        logits = x_proj @ E_refine.T    # (B, C)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fcf184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adj_from_hierarchy(class2hierarchy, n_classes, w_parent=1.0, w_sibling=0.1):\n",
    "    \"\"\"\n",
    "    Construit A_hat pour GCN en utilisant EXCLUSIVEMENT class2hierarchy.\n",
    "\n",
    "    - parent <-> enfant : poids = w_parent\n",
    "    - frÃ¨res/soeurs : poids = w_sibling\n",
    "    - auto-boucle : 1.0 (standard GCN)\n",
    "    \"\"\"\n",
    "\n",
    "    A = torch.zeros((n_classes, n_classes))\n",
    "\n",
    "    # ---- liens parent/enfant + siblings ----\n",
    "    for parent, children in class2hierarchy.items():\n",
    "\n",
    "        # parent <-> enfant\n",
    "        for c in children:\n",
    "            A[parent, c] = w_parent\n",
    "            A[c, parent] = w_parent\n",
    "\n",
    "        # siblings (enfants du mÃªme parent)\n",
    "        for i in range(len(children)):\n",
    "            for j in range(i + 1, len(children)):\n",
    "                c1, c2 = children[i], children[j]\n",
    "                A[c1, c2] = w_sibling\n",
    "                A[c2, c1] = w_sibling\n",
    "\n",
    "    # ---- self-loops ----\n",
    "    A = A + torch.eye(n_classes)\n",
    "\n",
    "    # ---- normalisation GCN ----\n",
    "    D = A.sum(dim=1)\n",
    "    D_inv_sqrt = torch.pow(D, -0.5)\n",
    "    D_inv_sqrt[torch.isinf(D_inv_sqrt)] = 0.0\n",
    "    D_mat = torch.diag(D_inv_sqrt)\n",
    "\n",
    "    A_hat = D_mat @ A @ D_mat\n",
    "    return A_hat\n",
    "\n",
    "def load_multilabel(path):\n",
    "    \"\"\"\n",
    "    Charge un fichier parent-enfant du type :\n",
    "    parent_id \\t child_id\n",
    "\n",
    "    Retourne :\n",
    "    {parent: [child, ...]}\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            p, c = line.strip().split(\"\\t\")\n",
    "            p, c = int(p), int(c)\n",
    "\n",
    "            if p not in mapping:\n",
    "                mapping[p] = []\n",
    "\n",
    "            mapping[p].append(c)\n",
    "\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "330b5003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_hat: torch.Size([531, 531]) Non-zero = 7611\n",
      "A_hat type: torch.float32\n",
      "A_hat device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ---------- CHARGEMENT HIÃ‰RARCHIE ----------\n",
    "CLASS_HIERARCHY_PATH = ROOT / \"class_hierarchy.txt\"\n",
    "class2hierarchy = load_multilabel(CLASS_HIERARCHY_PATH)\n",
    "\n",
    "A_hat = build_adj_from_hierarchy(class2hierarchy, n_classes).to(device)\n",
    "\n",
    "print(\"A_hat:\", A_hat.shape, \"Non-zero =\", (A_hat > 0).sum().item())\n",
    "print(\"A_hat type:\", A_hat.dtype)\n",
    "print(\"A_hat device:\", A_hat.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "739a6acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 110.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss=0.0493 | F1=0.2003\n",
      "New best model saved (F1=0.2003)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 116.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Loss=0.0189 | F1=0.4704\n",
      "New best model saved (F1=0.4704)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 121.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Loss=0.0164 | F1=0.5287\n",
      "New best model saved (F1=0.5287)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 128.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Loss=0.0153 | F1=0.5602\n",
      "New best model saved (F1=0.5602)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 121.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Loss=0.0145 | F1=0.5771\n",
      "New best model saved (F1=0.5771)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 79.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Loss=0.0138 | F1=0.5920\n",
      "New best model saved (F1=0.5920)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:05<00:00, 64.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Loss=0.0134 | F1=0.6048\n",
      "New best model saved (F1=0.6048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 89.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Loss=0.0130 | F1=0.6142\n",
      "New best model saved (F1=0.6142)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 125.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Loss=0.0127 | F1=0.6215\n",
      "New best model saved (F1=0.6215)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 114.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Loss=0.0125 | F1=0.6267\n",
      "New best model saved (F1=0.6267)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 123.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Loss=0.0123 | F1=0.6348\n",
      "New best model saved (F1=0.6348)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 125.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Loss=0.0120 | F1=0.6372\n",
      "New best model saved (F1=0.6372)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 126.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Loss=0.0119 | F1=0.6411\n",
      "New best model saved (F1=0.6411)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 127.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Loss=0.0118 | F1=0.6470\n",
      "New best model saved (F1=0.6470)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 127.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Loss=0.0116 | F1=0.6473\n",
      "New best model saved (F1=0.6473)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 122.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Loss=0.0115 | F1=0.6502\n",
      "New best model saved (F1=0.6502)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 99.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Loss=0.0114 | F1=0.6543\n",
      "New best model saved (F1=0.6543)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 94.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Loss=0.0113 | F1=0.6543\n",
      "New best model saved (F1=0.6543)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 95.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Loss=0.0113 | F1=0.6565\n",
      "New best model saved (F1=0.6565)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 90.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Loss=0.0112 | F1=0.6598\n",
      "New best model saved (F1=0.6598)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 86.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Loss=0.0111 | F1=0.6597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 83.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] Loss=0.0110 | F1=0.6608\n",
      "New best model saved (F1=0.6608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 97.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] Loss=0.0109 | F1=0.6622\n",
      "New best model saved (F1=0.6622)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 92.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] Loss=0.0110 | F1=0.6638\n",
      "New best model saved (F1=0.6638)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 97.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25] Loss=0.0109 | F1=0.6661\n",
      "New best model saved (F1=0.6661)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 95.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26] Loss=0.0108 | F1=0.6661\n",
      "New best model saved (F1=0.6661)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 106.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27] Loss=0.0108 | F1=0.6658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 87.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28] Loss=0.0108 | F1=0.6674\n",
      "New best model saved (F1=0.6674)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 104.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29] Loss=0.0107 | F1=0.6683\n",
      "New best model saved (F1=0.6683)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 95.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30] Loss=0.0107 | F1=0.6686\n",
      "New best model saved (F1=0.6686)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 94.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31] Loss=0.0106 | F1=0.6706\n",
      "New best model saved (F1=0.6706)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 85.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32] Loss=0.0105 | F1=0.6719\n",
      "New best model saved (F1=0.6719)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 94.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33] Loss=0.0105 | F1=0.6731\n",
      "New best model saved (F1=0.6731)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 83.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34] Loss=0.0104 | F1=0.6721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 77.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35] Loss=0.0104 | F1=0.6733\n",
      "New best model saved (F1=0.6733)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 99.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36] Loss=0.0104 | F1=0.6716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 96.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37] Loss=0.0104 | F1=0.6740\n",
      "New best model saved (F1=0.6740)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 81.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38] Loss=0.0103 | F1=0.6745\n",
      "New best model saved (F1=0.6745)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 83.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39] Loss=0.0103 | F1=0.6718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 77.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40] Loss=0.0103 | F1=0.6743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 88.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41] Loss=0.0103 | F1=0.6755\n",
      "New best model saved (F1=0.6755)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 91.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42] Loss=0.0102 | F1=0.6752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 108.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43] Loss=0.0102 | F1=0.6763\n",
      "New best model saved (F1=0.6763)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 83.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44] Loss=0.0102 | F1=0.6766\n",
      "New best model saved (F1=0.6766)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 102.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 45] Loss=0.0102 | F1=0.6777\n",
      "New best model saved (F1=0.6777)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 86.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 46] Loss=0.0101 | F1=0.6789\n",
      "New best model saved (F1=0.6789)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 84.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 47] Loss=0.0101 | F1=0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 88.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 48] Loss=0.0101 | F1=0.6770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 108.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49] Loss=0.0100 | F1=0.6766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 97.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 50] Loss=0.0100 | F1=0.6787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 124.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 51] Loss=0.0100 | F1=0.6796\n",
      "New best model saved (F1=0.6796)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 124.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 52] Loss=0.0100 | F1=0.6791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 122.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 53] Loss=0.0100 | F1=0.6805\n",
      "New best model saved (F1=0.6805)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:02<00:00, 123.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 54] Loss=0.0100 | F1=0.6804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 101.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 55] Loss=0.0099 | F1=0.6819\n",
      "New best model saved (F1=0.6819)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 110.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 56] Loss=0.0099 | F1=0.6822\n",
      "New best model saved (F1=0.6822)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 108.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 57] Loss=0.0099 | F1=0.6804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 109.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 58] Loss=0.0098 | F1=0.6823\n",
      "New best model saved (F1=0.6823)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 105.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 59] Loss=0.0098 | F1=0.6826\n",
      "New best model saved (F1=0.6826)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 105.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 60] Loss=0.0098 | F1=0.6804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 116.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 61] Loss=0.0098 | F1=0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 121.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 62] Loss=0.0098 | F1=0.6807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 118.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 63] Loss=0.0098 | F1=0.6813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 120.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 64] Loss=0.0097 | F1=0.6827\n",
      "New best model saved (F1=0.6827)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 122.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 65] Loss=0.0097 | F1=0.6836\n",
      "New best model saved (F1=0.6836)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 105.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 66] Loss=0.0097 | F1=0.6848\n",
      "New best model saved (F1=0.6848)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 116.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 67] Loss=0.0096 | F1=0.6848\n",
      "New best model saved (F1=0.6848)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 91.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 68] Loss=0.0097 | F1=0.6850\n",
      "New best model saved (F1=0.6850)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 115.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 69] Loss=0.0097 | F1=0.6831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 106.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 70] Loss=0.0096 | F1=0.6841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 106.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 71] Loss=0.0096 | F1=0.6848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 117.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 72] Loss=0.0096 | F1=0.6854\n",
      "New best model saved (F1=0.6854)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 113.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 73] Loss=0.0096 | F1=0.6860\n",
      "New best model saved (F1=0.6860)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 113.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 74] Loss=0.0096 | F1=0.6862\n",
      "New best model saved (F1=0.6862)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 106.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 75] Loss=0.0096 | F1=0.6870\n",
      "New best model saved (F1=0.6870)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 95.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 76] Loss=0.0096 | F1=0.6850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 90.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 77] Loss=0.0095 | F1=0.6853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:04<00:00, 86.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 78] Loss=0.0095 | F1=0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 115.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 79] Loss=0.0095 | F1=0.6865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:03<00:00, 107.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 80] Loss=0.0095 | F1=0.6857\n",
      "Early stopping triggered\n",
      "\n",
      "ðŸŽ‰ Final best F1: 0.6870291590027093\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# ----------------------------\n",
    "# Hyperparameters\n",
    "# ----------------------------\n",
    "epochs = 100\n",
    "patience = 5\n",
    "wait = 0\n",
    "best_f1 = 0\n",
    "\n",
    "alpha_ema = 0.99       # teacher EMA speed\n",
    "lambda_cons = 0.5     # weight for consistency loss\n",
    "noise_std = 0.05        # noise on student input\n",
    "\n",
    "# ----------------------------\n",
    "# Init student + teacher\n",
    "# ----------------------------\n",
    "student = GCNEnhancedClassifier(\n",
    "    input_dim=X_train.size(1),\n",
    "    label_init_emb=label_emb,\n",
    "    A_hat=A_hat,\n",
    "    num_layers=3,\n",
    "    dropout=0.2        # student = bruit\n",
    ").to(device)\n",
    "\n",
    "teacher = GCNEnhancedClassifier(\n",
    "    input_dim=X_train.size(1),\n",
    "    label_init_emb=label_emb,\n",
    "    A_hat=A_hat,\n",
    "    num_layers=3,\n",
    "    dropout=0.0        # teacher = STABLE\n",
    ").to(device)\n",
    "\n",
    "teacher.load_state_dict(student.state_dict())\n",
    "\n",
    "optimizer = torch.optim.AdamW(student.parameters(), lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "best_teacher = copy.deepcopy(teacher.state_dict())\n",
    "\n",
    "# ----------------------------\n",
    "# Consistency loss\n",
    "# ----------------------------\n",
    "def consistency_loss(log_s, log_t):\n",
    "    ps = torch.sigmoid(log_s)\n",
    "    pt = torch.sigmoid(log_t)\n",
    "    return F.mse_loss(ps, pt)\n",
    "\n",
    "# ----------------------------\n",
    "# Training loop\n",
    "# ----------------------------\n",
    "for epoch in range(1, epochs + 1):\n",
    "    student.train()\n",
    "    teacher.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        X = batch[\"X\"].to(device)\n",
    "        y = batch[\"y\"].to(device)\n",
    "\n",
    "        # Add noise to student\n",
    "        noisy_X = X + noise_std * torch.randn_like(X)\n",
    "\n",
    "        # student forward\n",
    "        logits_s = student(noisy_X)\n",
    "\n",
    "        # teacher forward (no gradient)\n",
    "        with torch.no_grad():\n",
    "            logits_t = teacher(X)\n",
    "\n",
    "        # supervised = main objective\n",
    "        loss_sup = F.binary_cross_entropy_with_logits(logits_s, y)\n",
    "\n",
    "        # consistency = stability objective\n",
    "        loss_cons = consistency_loss(logits_s, logits_t)\n",
    "\n",
    "        # total loss\n",
    "        loss = loss_sup + lambda_cons * loss_cons\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # EMA update (teacher â†’ student)\n",
    "        for t_param, s_param in zip(teacher.parameters(), student.parameters()):\n",
    "            t_param.data = alpha_ema * t_param.data + (1 - alpha_ema) * s_param.data\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    teacher.eval()\n",
    "    f1_sample, f1_macro = evaluate(teacher, val_loader)\n",
    "\n",
    "    print(f\"[Epoch {epoch}] Loss={total_loss/len(train_loader):.4f} | F1={f1_sample:.4f}\")\n",
    "\n",
    "    if f1_sample > best_f1:\n",
    "        best_f1 = f1_sample\n",
    "        best_teacher = copy.deepcopy(teacher.state_dict())\n",
    "        wait = 0\n",
    "        print(f\"New best model saved (F1={best_f1:.4f})\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "\n",
    "teacher.load_state_dict(best_teacher)\n",
    "print(\"\\nðŸŽ‰ Final best F1:\", best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7a49347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating submission...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [00:00<00:00, 416.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Submission saved â†’ Submission\\submission_GNN.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\nGenerating submission...\")\n",
    "\n",
    "teacher.eval()\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "\n",
    "def select_k(prob, min_k=2, max_k=3):\n",
    "    idx = np.argsort(prob)[::-1]  # descend\n",
    "    top3 = idx[:max_k]\n",
    "\n",
    "    if prob[top3[2]] < 0.25 * prob[top3[1]]:\n",
    "        return top3[:2]\n",
    "\n",
    "    return top3\n",
    "\n",
    "\n",
    "preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for start in tqdm(range(0, len(X_test), 64)):\n",
    "        batch = X_test[start:start+64]\n",
    "        logits = teacher(batch, use_dropout=False)\n",
    "\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "        for p in probs:\n",
    "            labels = select_k(p)\n",
    "            preds.append([str(x) for x in labels])\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# SAVE CSV\n",
    "# ==========================================================\n",
    "\n",
    "OUT_DIR = Path(\"Submission\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "OUT_PATH = OUT_DIR / \"submission_GNN.csv\"\n",
    "\n",
    "with open(OUT_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"id\", \"label\"])\n",
    "    for pid, labels in zip(test_ids, preds):\n",
    "        w.writerow([pid, \",\".join(labels)])\n",
    "\n",
    "print(f\"ðŸŽ‰ Submission saved â†’ {OUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
