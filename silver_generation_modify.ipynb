{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7419c2a8-6739-4ed6-b9ee-3eeb108873de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from utils import * \n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e33d512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default paths\n",
    "ROOT = Path(\"Amazon_products\") # Root Amazon_products directory\n",
    "TRAIN_DIR = ROOT / \"train\"\n",
    "TEST_DIR = ROOT / \"test\"\n",
    "\n",
    "TEST_CORPUS_PATH = os.path.join(TEST_DIR, \"test_corpus.txt\")  # product_id \\t text\n",
    "TRAIN_CORPUS_PATH = os.path.join(TRAIN_DIR, \"train_corpus.txt\")\n",
    "\n",
    "CLASS_HIERARCHY_PATH = ROOT / \"class_hierarchy.txt\" \n",
    "CLASS_RELATED_PATH = ROOT / \"class_related_keywords.txt\" \n",
    "CLASS_PATH = ROOT / \"classes.txt\" \n",
    "\n",
    "SUBMISSION_PATH = \"Submission/submission.csv\"  # output file\n",
    "\n",
    "# --- Constants ---\n",
    "NUM_CLASSES = 531  # total number of classes (0â€“530)\n",
    "MIN_LABELS = 1     # minimum number of labels per sample\n",
    "MAX_LABELS = 3     # maximum number of labels per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "257bd473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load ---\n",
    "def load_corpus(path):\n",
    "    \"\"\"Load test corpus into {id: text} dictionary.\"\"\"\n",
    "    id2text = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\", 1)\n",
    "            if len(parts) == 2:\n",
    "                id, text = parts\n",
    "                id2text[id] = text\n",
    "    return id2text\n",
    "\n",
    "def load_multilabel(path):\n",
    "    \"\"\"Load multi-label data into {id: [labels]} dictionary.\"\"\"\n",
    "    id2labels = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) == 2:\n",
    "                pid, label = parts\n",
    "                pid = int(pid)\n",
    "                label = int(label)\n",
    "\n",
    "                if pid not in id2labels:\n",
    "                    id2labels[pid] = []\n",
    "\n",
    "                id2labels[pid].append(label)\n",
    "    return id2labels\n",
    "\n",
    "def load_class_keywords(path):\n",
    "    \"\"\"Load class keywords into {class_name: [keywords]} dictionary.\"\"\"\n",
    "    class2keywords = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if \":\" not in line:\n",
    "                continue\n",
    "            classname, keywords = line.strip().split(\":\", 1)\n",
    "            keyword_list = [kw.strip() for kw in keywords.split(\",\") if kw.strip()]\n",
    "            class2keywords[classname] = keyword_list\n",
    "    return class2keywords\n",
    "\n",
    "id2text_test = load_corpus(TEST_CORPUS_PATH)\n",
    "id_list_test = list(id2text_test.keys())\n",
    "\n",
    "id2text_train = load_corpus(TRAIN_CORPUS_PATH)\n",
    "id_list_train = list(id2text_train.keys())\n",
    "\n",
    "id2class = load_corpus(CLASS_PATH)\n",
    "class2hierarchy = load_multilabel(CLASS_HIERARCHY_PATH)\n",
    "class2related = load_class_keywords(CLASS_RELATED_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19ec71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_stats(name, silver):\n",
    "    counts = [len(v) for v in silver.values()]\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"  Documents: {len(counts)}\")\n",
    "    print(f\"  Avg labels/doc: {np.mean(counts):.2f}\")\n",
    "    print(f\"  Min labels: {np.min(counts)}\")\n",
    "    print(f\"  Max labels: {np.max(counts)}\")\n",
    "\n",
    "def hierarchy_consistency(silver, hierarchy):\n",
    "    ok = total = 0\n",
    "    for labels in silver.values():\n",
    "        L = set(labels)\n",
    "        for parent, children in hierarchy.items():\n",
    "            for child in children:\n",
    "                if child in L:\n",
    "                    total += 1\n",
    "                    if parent in L:\n",
    "                        ok += 1\n",
    "    return ok / total if total > 0 else 0\n",
    "\n",
    "def count_present_classes(silver, total_classes=531):\n",
    "    # Collect all unique labels appearing in the dataset\n",
    "    all_labels = set(label for labels in silver.values() for label in labels)\n",
    "    \n",
    "    # Count how many distinct classes are present\n",
    "    n_present = len(all_labels)\n",
    "    \n",
    "    print(f\"Present classes: {n_present}/{total_classes} ({n_present/total_classes*100:.2f}%)\")\n",
    "    return n_present\n",
    "\n",
    "from collections import Counter\n",
    "def analyze_coverage(silver, name):\n",
    "    all_labels = []\n",
    "    for info in silver.values():\n",
    "        all_labels.extend(info)\n",
    "    \n",
    "    unique = len(set(all_labels))\n",
    "    counter = Counter(all_labels)\n",
    "    top5 = counter.most_common(5)\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Coverage: {unique}/531 ({unique/531*100:.1f}%)\")\n",
    "    print(f\"  Top-5 most frequent:\")\n",
    "    for cls, count in top5:\n",
    "        print(f\"    Class {cls}: {count} times ({count/len(silver)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c29d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_with_hierarchy(core_labels, hierarchy):\n",
    "    \"\"\"Add parents in the hierarchy\"\"\"\n",
    "    expanded = set(core_labels)\n",
    "    \n",
    "    for label in core_labels:\n",
    "        for parent, children in hierarchy.items():\n",
    "            if label in children:\n",
    "                expanded.add(parent)\n",
    "                expanded.update(expand_with_hierarchy([parent], hierarchy))\n",
    "    \n",
    "    # Keep 3 more specific\n",
    "    return sorted(list(expanded))[:3]\n",
    "\n",
    "\n",
    "def propagate_hierarchy_simple(\n",
    "    label_embeddings,\n",
    "    class_hierarchy,\n",
    "    alpha=0.5,\n",
    "    include_children=True,\n",
    "    normalize=True\n",
    "):\n",
    "    device = label_embeddings.device\n",
    "    num_classes = label_embeddings.shape[0]\n",
    "    updated = label_embeddings.clone()\n",
    "    \n",
    "    # Pass 1: Parents â†’ Children\n",
    "    for class_id in range(num_classes):\n",
    "        class_id_str = str(class_id)\n",
    "        \n",
    "        if class_id_str not in class_hierarchy:\n",
    "            continue\n",
    "        \n",
    "        parents = class_hierarchy[class_id_str].get(\"parents\", [])\n",
    "        valid_parents = [p for p in parents if 0 <= p < num_classes]\n",
    "        \n",
    "        if valid_parents:\n",
    "            parent_vec = label_embeddings[valid_parents].mean(dim=0)\n",
    "            updated[class_id] = (1 - alpha) * label_embeddings[class_id] + alpha * parent_vec\n",
    "    \n",
    "    # Pass 2: Children â†’ Parents\n",
    "    if include_children:\n",
    "        temp = updated.clone()\n",
    "        for class_id in range(num_classes):\n",
    "            class_id_str = str(class_id)\n",
    "            \n",
    "            if class_id_str not in class_hierarchy:\n",
    "                continue\n",
    "            \n",
    "            children = class_hierarchy[class_id_str].get(\"children\", [])\n",
    "            valid_children = [c for c in children if 0 <= c < num_classes]\n",
    "            \n",
    "            if valid_children:\n",
    "                children_vec = updated[valid_children].mean(dim=0)\n",
    "                temp[class_id] = (1 - alpha) * updated[class_id] + alpha * children_vec\n",
    "        \n",
    "        updated = temp\n",
    "    \n",
    "    # Normalize\n",
    "    if normalize:\n",
    "        norms = torch.norm(updated, dim=1, keepdim=True)\n",
    "        updated = updated / (norms + 1e-8)\n",
    "    \n",
    "    return updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcb64f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "GENERATING TRAIN SILVER LABELS (FAST)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enriching: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 531/531 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Encoding 531 texts on cuda:0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Saved to Embeddings/labels_base.pt\n",
      "base_category_embeddings is already torch\n",
      "âš™ï¸ Encoding 49145 texts on cuda:0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 768/768 [10:52<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Saved to Embeddings/X_train_test.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49145/49145 [00:04<00:00, 10178.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Safe Train\n",
      "  Documents: 29487\n",
      "  Avg labels/doc: 3.00\n",
      "  Min labels: 3\n",
      "  Max labels: 3\n"
     ]
    }
   ],
   "source": [
    "model_name = \"all-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "model = model.to(device)\n",
    "\n",
    "def get_embeddings(texts, model, batch_size=64, save_path=None, force_recompute=False):\n",
    "\n",
    "    # Load cache\n",
    "    if save_path and os.path.exists(save_path) and not force_recompute:\n",
    "        print(f\"ðŸ“¦ Loading from {save_path}\")\n",
    "        emb = torch.load(save_path, map_location=\"cpu\")\n",
    "        if isinstance(emb, np.ndarray):\n",
    "            emb = torch.from_numpy(emb)\n",
    "        return emb\n",
    "\n",
    "    print(f\"âš™ï¸ Encoding {len(texts)} texts on {model.device}...\")\n",
    "\n",
    "    # ---- ENCODE ----\n",
    "    emb = model.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_tensor=True,   # ðŸ”¥ GARANTI torch.Tensor\n",
    "        device=model.device\n",
    "    )\n",
    "\n",
    "    # ---- SAFETY CHECK ----\n",
    "    if isinstance(emb, list):\n",
    "        print(\"âš ï¸ encode returned list â†’ converting to tensor\")\n",
    "        emb = torch.stack([e for e in emb])  # assume each e is tensor\n",
    "\n",
    "    elif isinstance(emb, np.ndarray):\n",
    "        print(\"âš ï¸ encode returned numpy â†’ converting to tensor\")\n",
    "        emb = torch.from_numpy(emb)\n",
    "\n",
    "    # ---- CPU for saving ----\n",
    "    emb = emb.cpu()\n",
    "\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        torch.save(emb, save_path)\n",
    "        print(f\"ðŸ’¾ Saved to {save_path}\")\n",
    "\n",
    "    return emb\n",
    "\n",
    "\n",
    "def get_enriched_category_text(class_id, id2class, class2related, max_keywords=10):\n",
    "    class_name = id2class[str(class_id)]\n",
    "    \n",
    "    # Replace underscore with space for better understanding\n",
    "    clean_name = class_name.replace('_', ' ')\n",
    "    \n",
    "    # Add keywords if available\n",
    "    if class_name in class2related:\n",
    "        keywords = class2related[class_name][:max_keywords]\n",
    "        keywords_str = \" \".join(keywords)\n",
    "        enriched = f\"{clean_name} {keywords_str}\"\n",
    "    else:\n",
    "        enriched = clean_name\n",
    "    \n",
    "    return enriched\n",
    "\n",
    "\n",
    "def get_enriched_category_with_hierarchy(class_id, id2class, class2related, class_hierarchy, max_keywords=10):\n",
    "    class_name = id2class[str(class_id)]\n",
    "    clean_name = class_name.replace('_', ' ')\n",
    "    \n",
    "    # Parents\n",
    "    parents = class_hierarchy.get(str(class_id), {}).get(\"parents\", [])\n",
    "    parent_names = []\n",
    "    for p in parents:\n",
    "        if 0 <= p < 531:\n",
    "            parent_name = id2class[str(p)].replace('_', ' ')\n",
    "            if parent_name.lower() != \"root\":\n",
    "                parent_names.append(parent_name)\n",
    "    \n",
    "    # Keywords\n",
    "    keywords = class2related.get(class_name, [])[:max_keywords]\n",
    "    \n",
    "    # Combine\n",
    "    parts = [clean_name]\n",
    "    if parent_names:\n",
    "        parts.extend(parent_names)\n",
    "    if keywords:\n",
    "        parts.extend(keywords)\n",
    "    \n",
    "    return \" \".join(parts)\n",
    "\n",
    "\n",
    "def generate_silver_labels_FAST(\n",
    "    train_texts,\n",
    "    train_ids,\n",
    "    test_texts,\n",
    "    test_ids,\n",
    "    id2class,\n",
    "    class2related,\n",
    "    tokenizer,\n",
    "    model,\n",
    "    class_hierarchy,\n",
    "    output_path_train=\"Silver/silver_train_true.json\",\n",
    "    output_path_test=\"Silver/silver_test_true.json\"\n",
    "):\n",
    "    \n",
    "    all_texts = train_texts + test_texts\n",
    "    all_ids = train_ids + test_ids\n",
    "\n",
    "    enriched_categories = [\n",
    "        get_enriched_category_with_hierarchy(i, id2class, class2related, class_hierarchy)\n",
    "        for i in tqdm(range(531), desc=\"Enriching\")\n",
    "    ]\n",
    "\n",
    "    base_category_embeddings = get_embeddings(\n",
    "        enriched_categories,\n",
    "        model=model,\n",
    "        batch_size=64,\n",
    "        save_path=\"Embeddings/labels_base.pt\",\n",
    "        force_recompute=True\n",
    "    )\n",
    "\n",
    "    hierarchy_int = {}\n",
    "    for cid, rel in class_hierarchy.items():\n",
    "        parents = rel.get(\"parents\", []) if isinstance(rel, dict) else []\n",
    "        children = rel.get(\"children\", []) if isinstance(rel, dict) else rel if isinstance(rel, list) else []\n",
    "        hierarchy_int[cid] = {\"parents\": parents, \"children\": children}\n",
    "\n",
    "    # Ensure tensor format\n",
    "    if isinstance(base_category_embeddings, list):\n",
    "        print(\"base_category_embeddings is list â†’ stacking\")\n",
    "        base_category_embeddings = torch.stack(base_category_embeddings)\n",
    "    elif isinstance(base_category_embeddings, np.ndarray):\n",
    "        print(\"base_category_embeddings is numpy â†’ converting\")\n",
    "        base_category_embeddings = torch.from_numpy(base_category_embeddings)\n",
    "    elif isinstance(base_category_embeddings, torch.Tensor):\n",
    "        print(\"base_category_embeddings is already torch\")\n",
    "    else:\n",
    "        raise TypeError(f\"Unexpected type: {type(base_category_embeddings)}\")\n",
    "    \n",
    "    hierarchical_embeddings = propagate_hierarchy_simple(\n",
    "        label_embeddings=base_category_embeddings,\n",
    "        class_hierarchy=hierarchy_int,\n",
    "        alpha=0.5,\n",
    "        include_children=True,\n",
    "        normalize=True\n",
    "    )\n",
    "\n",
    "    torch.save(hierarchical_embeddings, \"Embeddings/labels_hierarchical.pt\")\n",
    "\n",
    "    review_embeddings = get_embeddings(\n",
    "        all_texts,\n",
    "        model=model,\n",
    "        batch_size=64,\n",
    "        save_path=\"Embeddings/X_train_test.pt\",\n",
    "        force_recompute=True\n",
    "    )\n",
    "\n",
    "    # Ensure both are tensors\n",
    "    if isinstance(review_embeddings, np.ndarray):\n",
    "        review_embeddings = torch.from_numpy(review_embeddings)\n",
    "    if isinstance(hierarchical_embeddings, np.ndarray):\n",
    "        hierarchical_embeddings = torch.from_numpy(hierarchical_embeddings)\n",
    "\n",
    "    # Move to device for computation\n",
    "    review_embeddings = review_embeddings.to(device)\n",
    "    hierarchical_embeddings = hierarchical_embeddings.to(device)\n",
    "\n",
    "    # Compute similarity on device\n",
    "    all_similarities = torch.matmul(\n",
    "        review_embeddings,\n",
    "        hierarchical_embeddings.T\n",
    "    )\n",
    "\n",
    "    # Move back to CPU for numpy operations\n",
    "    all_similarities = all_similarities.cpu()\n",
    "\n",
    "    silver_train, silver_test = {}, {}\n",
    "    n_train = len(train_ids)\n",
    "\n",
    "    for idx, rid in enumerate(tqdm(all_ids, desc=\"Assigning\")):\n",
    "\n",
    "        sims = all_similarities[idx]\n",
    "        topk_scores, topk_idx = torch.topk(sims, k=3)\n",
    "        \n",
    "        topk_idx = topk_idx.tolist()\n",
    "        topk_scores = topk_scores.tolist()\n",
    "\n",
    "        expanded = expand_with_hierarchy(topk_idx, class_hierarchy)\n",
    "        \n",
    "        # Convert scores to pseudo-probabilities\n",
    "        probs = torch.softmax(torch.tensor(topk_scores) * 5, dim=0).tolist()\n",
    "\n",
    "        record = {\n",
    "            \"labels\": expanded[:3],\n",
    "            \"scores\": topk_scores[:3],\n",
    "            \"probs\": probs[:3]\n",
    "        }\n",
    "\n",
    "        if idx < n_train:\n",
    "            silver_train[rid] = record\n",
    "        else:\n",
    "            silver_test[rid] = record\n",
    "\n",
    "    os.makedirs(\"Silver\", exist_ok=True)\n",
    "\n",
    "    json.dump(silver_train, open(output_path_train, \"w\", encoding=\"utf-8\"), indent=2, ensure_ascii=False)\n",
    "    json.dump(silver_test, open(output_path_test, \"w\", encoding=\"utf-8\"), indent=2, ensure_ascii=False)\n",
    "\n",
    "    return silver_train, silver_test\n",
    "\n",
    "\n",
    "# Exec\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GENERATING TRAIN SILVER LABELS (FAST)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "silver_train_safe, silver_test_safe = generate_silver_labels_FAST(\n",
    "    list(id2text_train.values()),\n",
    "    list(id2text_train.keys()),\n",
    "    list(id2text_test.values()),\n",
    "    list(id2text_test.keys()),\n",
    "    id2class,\n",
    "    class2related,\n",
    "    None,\n",
    "    model,\n",
    "    class2hierarchy,\n",
    "    output_path_train=\"Silver/silver_train_modify.json\",\n",
    "    output_path_test=\"Silver/silver_test_modify.json\"\n",
    ")\n",
    "\n",
    "# Stats\n",
    "print()\n",
    "label_stats(\"Safe Train\", silver_train_safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4252737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hierarchy Consistency: 99.01%\n"
     ]
    }
   ],
   "source": [
    "silver_train_labels_only = {\n",
    "    pid: info[\"labels\"]\n",
    "    for pid, info in silver_train_safe.items()\n",
    "}\n",
    "\n",
    "consistency = hierarchy_consistency(silver_train_labels_only, class2hierarchy)\n",
    "print(f\"\\nHierarchy Consistency: {consistency:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c5ef0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 50.28%\n",
      "Covered classes: 267/531\n"
     ]
    }
   ],
   "source": [
    "def label_coverage(silver_labels, num_classes=531):\n",
    "    \"\"\"\n",
    "    silver_labels : { review_id: [label1, label2, ...] }\n",
    "    returns coverage_ratio, covered_classes\n",
    "    \"\"\"\n",
    "    covered = set()\n",
    "\n",
    "    for _, labels in silver_labels.items():\n",
    "        for lbl in labels:\n",
    "            if 0 <= lbl < num_classes:\n",
    "                covered.add(lbl)\n",
    "\n",
    "    coverage_ratio = len(covered) / num_classes\n",
    "    return coverage_ratio, sorted(list(covered))\n",
    "\n",
    "coverage, classes = label_coverage(silver_train_labels_only)\n",
    "print(f\"Coverage: {coverage:.2%}\")\n",
    "print(f\"Covered classes: {len(classes)}/{531}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a90a22",
   "metadata": {},
   "source": [
    "# TODO faire test + train et labels embeddings avec hierarchy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
