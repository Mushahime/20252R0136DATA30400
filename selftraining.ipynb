{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df6eca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Device: cuda\n",
      "Train IDs: 29487 | Test IDs: 19658\n",
      "\n",
      "üß† Loading X_all.pt ...\n",
      "‚úì X_train: torch.Size([29487, 768]) | X_test: torch.Size([19658, 768])\n",
      "‚úì Label embeddings: torch.Size([531, 768])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIGURATION\n",
    "# ==========================================================\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üîß Device: {device}\")\n",
    "\n",
    "# Paths\n",
    "ROOT = Path(\"Amazon_products\")\n",
    "TRAIN_CORPUS_PATH = ROOT / \"train\" / \"train_corpus.txt\"\n",
    "TEST_CORPUS_PATH  = ROOT / \"test\" / \"test_corpus.txt\"\n",
    "CLASS_PATH        = ROOT / \"classes.txt\"\n",
    "\n",
    "EMB_DIR          = Path(\"Embeddings\")\n",
    "X_ALL_PATH       = EMB_DIR / \"X_train_test.pt\"\n",
    "LABEL_EMB_PATH   = EMB_DIR / \"labels_hierarchical.pt\"\n",
    "\n",
    "MODEL_SAVE = Path(\"Models\")\n",
    "MODEL_SAVE.mkdir(exist_ok=True)\n",
    "MODEL_PATH = MODEL_SAVE / \"silver_classifier.pt\"\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD IDS\n",
    "# ==========================================================\n",
    "def load_ids(path):\n",
    "    ids = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            pid, _ = line.strip().split(\"\\t\", 1)\n",
    "            ids.append(int(pid))\n",
    "    return ids\n",
    "\n",
    "train_ids = load_ids(TRAIN_CORPUS_PATH)\n",
    "test_ids  = load_ids(TEST_CORPUS_PATH)\n",
    "n_train = len(train_ids)\n",
    "n_test  = len(test_ids)\n",
    "\n",
    "print(f\"Train IDs: {n_train} | Test IDs: {n_test}\")\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD SILVER LABELS\n",
    "# ==========================================================\n",
    "with open(\"Silver/silver_train_modify.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "silver_labels = {int(pid): data[\"labels\"] for pid, data in raw.items()}\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD X_all\n",
    "# ==========================================================\n",
    "print(\"\\nüß† Loading X_all.pt ...\")\n",
    "data = torch.load(X_ALL_PATH, weights_only=False)\n",
    "\n",
    "if isinstance(data, np.ndarray):\n",
    "    data = torch.from_numpy(data)\n",
    "elif isinstance(data, list):\n",
    "    data = torch.stack(data)\n",
    "\n",
    "X_all = data.float().to(device)\n",
    "assert X_all.shape[0] == n_train + n_test\n",
    "\n",
    "X_train = X_all[:n_train]\n",
    "X_test  = X_all[n_train:]\n",
    "print(f\"‚úì X_train: {X_train.shape} | X_test: {X_test.shape}\")\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD LABEL EMBEDDINGS\n",
    "# ==========================================================\n",
    "tmp = torch.load(LABEL_EMB_PATH, weights_only=False)\n",
    "\n",
    "# Convertir numpy ‚Üí tensor si n√©cessaire\n",
    "if isinstance(tmp, np.ndarray):\n",
    "    tmp = torch.from_numpy(tmp)\n",
    "\n",
    "label_emb = tmp.float().to(device)\n",
    "print(f\"‚úì Label embeddings: {label_emb.shape}\")\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD CLASS NAMES\n",
    "# ==========================================================\n",
    "classes = {}\n",
    "with open(CLASS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        cid, cname = line.strip().split(\"\\t\")\n",
    "        classes[int(cid)] = cname\n",
    "\n",
    "n_classes = len(classes)\n",
    "\n",
    "pid2idx = {pid: i for i, pid in enumerate(train_ids)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b455aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, pids, labels_dict):\n",
    "        self.pids = pids\n",
    "        self.labels = labels_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pid = self.pids[idx]\n",
    "        emb = X_train[pid2idx[pid]]\n",
    "\n",
    "        y = torch.zeros(n_classes)\n",
    "        for c in self.labels[pid]:\n",
    "            if 0 <= c < n_classes:\n",
    "                y[c] = 1.0\n",
    "\n",
    "        return {\"X\": emb, \"y\": y}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2efee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p, val_p = train_test_split(\n",
    "    list(silver_labels.keys()), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = MultiLabelDataset(train_p, silver_labels)\n",
    "val_dataset   = MultiLabelDataset(val_p, silver_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eb16631",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InnerProductClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, label_embeddings, dropout=0.2, trainable_label_emb=False):\n",
    "        super().__init__()\n",
    "\n",
    "        D = label_embeddings.size(1)\n",
    "\n",
    "        self.proj = nn.Linear(input_dim, D)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        if trainable_label_emb:\n",
    "            self.label_emb = nn.Parameter(label_embeddings.clone())\n",
    "        else:\n",
    "            self.register_buffer(\"label_emb\", label_embeddings.clone())\n",
    "\n",
    "    def forward(self, x, use_dropout=True):\n",
    "        if use_dropout:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x_proj = self.proj(x)                 # (B, D)\n",
    "        logits = x_proj @ self.label_emb.T    # (B, C)\n",
    "\n",
    "        return logits\n",
    "\n",
    "model = InnerProductClassifier(\n",
    "    input_dim = X_train.size(1),\n",
    "    label_embeddings = label_emb,\n",
    "    dropout = 0.2,\n",
    "    trainable_label_emb = False\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6c91e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, thr=0.25):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            X = batch[\"X\"]\n",
    "            y = batch[\"y\"].numpy()\n",
    "\n",
    "            prob = torch.sigmoid(model(X)).cpu().numpy()\n",
    "            pred = (prob > thr).astype(int)\n",
    "\n",
    "            preds.extend(pred)\n",
    "            labels.extend(y)\n",
    "\n",
    "    f1s = f1_score(labels, preds, average=\"samples\")\n",
    "    f1m = f1_score(labels, preds, average=\"macro\")\n",
    "    return f1s, f1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62bfb93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:02<00:00, 148.00it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss=0.0911 | F1=0.0000\n",
      "üî• New best model saved (0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:02<00:00, 159.63it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] loss=0.0360 | F1=0.0026\n",
      "üî• New best model saved (0.0026)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:02<00:00, 153.52it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] loss=0.0293 | F1=0.0789\n",
      "üî• New best model saved (0.0789)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:02<00:00, 152.42it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] loss=0.0252 | F1=0.1970\n",
      "üî• New best model saved (0.1970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:02<00:00, 149.14it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] loss=0.0224 | F1=0.3071\n",
      "üî• New best model saved (0.3071)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:02<00:00, 136.02it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] loss=0.0203 | F1=0.3937\n",
      "üî• New best model saved (0.3937)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:02<00:00, 139.71it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] loss=0.0188 | F1=0.4550\n",
      "üî• New best model saved (0.4550)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:02<00:00, 148.46it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] loss=0.0175 | F1=0.4985\n",
      "üî• New best model saved (0.4985)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:02<00:00, 156.29it/s]\n",
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] loss=0.0164 | F1=0.5330\n",
      "üî• New best model saved (0.5330)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:02<00:00, 157.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] loss=0.0155 | F1=0.5614\n",
      "üî• New best model saved (0.5614)\n",
      "\n",
      "üéâ Best validation F1 = 0.5614\n",
      "üì¶ Model saved at: Models\\silver_classifier.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\noamc\\Documents\\insa_korea\\Cours\\big data\\final proj\\project_release\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüöÄ Training...\")\n",
    "best = 0\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    total = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        X = batch[\"X\"]\n",
    "        y = batch[\"y\"].to(device)\n",
    "\n",
    "        logits = model(X)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += loss.item()\n",
    "\n",
    "    f1s, f1m = evaluate(model, val_loader)\n",
    "    print(f\"[Epoch {epoch}] loss={total/len(train_loader):.4f} | F1={f1s:.4f}\")\n",
    "\n",
    "    if f1s > best:\n",
    "        best = f1s\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        print(f\"üî• New best model saved ({best:.4f})\")\n",
    "\n",
    "print(f\"\\nüéâ Best validation F1 = {best:.4f}\")\n",
    "print(f\"üì¶ Model saved at: {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1b44c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Generating submission...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/308 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 308/308 [00:02<00:00, 127.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Submission saved ‚Üí Submission\\submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "print(\"\\nüìù Generating submission...\")\n",
    "\n",
    "# Reload best model\n",
    "best_model = InnerProductClassifier(\n",
    "    input_dim=X_train.size(1),\n",
    "    label_embeddings=label_emb,\n",
    "    dropout=0.2,\n",
    "    trainable_label_emb=False\n",
    ").to(device)\n",
    "\n",
    "best_model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "best_model.eval()\n",
    "\n",
    "# Parameters from your ORIGINAL code\n",
    "THR = 0.5\n",
    "MIN_L = 2\n",
    "MAX_L = 3\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "\n",
    "preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for start in tqdm(range(0, len(X_test), 64)):\n",
    "        batch = X_test[start:start+64]\n",
    "\n",
    "        # disable dropout\n",
    "        logits = best_model(batch, use_dropout=False)\n",
    "\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "        for p in probs:\n",
    "            pred = (p > THR).astype(int)\n",
    "\n",
    "            # ===== YOUR POST-PROCESSING RULES =====\n",
    "            if pred.sum() == 0:\n",
    "                pred[np.argsort(p)[-MIN_L:]] = 1\n",
    "            elif pred.sum() == 1:\n",
    "                pred[np.argsort(p)[-2:]] = 1\n",
    "            elif pred.sum() > MAX_L:\n",
    "                pred = np.zeros_like(pred)\n",
    "                pred[np.argsort(p)[-MAX_L:]] = 1\n",
    "\n",
    "            labels = [str(i) for i, v in enumerate(pred) if v == 1]\n",
    "            preds.append(labels)\n",
    "\n",
    "# ==========================================================\n",
    "# SAVE CSV\n",
    "# ==========================================================\n",
    "\n",
    "OUT_DIR = Path(\"Submission\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "OUT_PATH = OUT_DIR / \"submission.csv\"\n",
    "\n",
    "with open(OUT_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"id\", \"label\"])\n",
    "    for pid, labels in zip(test_ids, preds):\n",
    "        w.writerow([pid, \",\".join(labels)])\n",
    "\n",
    "print(f\"üéâ Submission saved ‚Üí {OUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
