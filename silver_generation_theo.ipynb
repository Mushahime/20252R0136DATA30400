{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7419c2a8-6739-4ed6-b9ee-3eeb108873de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from utils import * \n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33d512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default paths\n",
    "ROOT = Path(\"Amazon_products\") # Root Amazon_products directory\n",
    "TRAIN_DIR = ROOT / \"train\"\n",
    "TEST_DIR = ROOT / \"test\"\n",
    "\n",
    "TEST_CORPUS_PATH = os.path.join(TEST_DIR, \"test_corpus.txt\")  # product_id \\t text\n",
    "TRAIN_CORPUS_PATH = os.path.join(TRAIN_DIR, \"train_corpus.txt\")\n",
    "\n",
    "CLASS_HIERARCHY_PATH = ROOT / \"class_hierarchy.txt\" \n",
    "CLASS_RELATED_PATH = ROOT / \"class_related_keywords.txt\" \n",
    "CLASS_PATH = ROOT / \"classes.txt\" \n",
    "\n",
    "SUBMISSION_PATH = \"Submission/submission.csv\"  # output file\n",
    "\n",
    "# --- Constants ---\n",
    "NUM_CLASSES = 531  # total number of classes (0â€“530)\n",
    "MIN_LABELS = 2     # minimum number of labels per sample\n",
    "MAX_LABELS = 3     # maximum number of labels per sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "257bd473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531\n",
      "0 : grocery_gourmet_food\n",
      "1 : meat_poultry\n",
      "2 : jerky\n",
      "3 : toys_games\n",
      "4 : games\n",
      "5 : puzzles\n",
      "6 : jigsaw_puzzles\n",
      "7 : board_games\n",
      "8 : beverages\n",
      "9 : juices\n",
      "\n",
      "19658\n",
      "0 : conair cs15tcs professional straight styles straightening iron woah ! sure this straightener looks like all the other crappy straightners in the world , but there 's a twist to this one ! it is my first straightner and i 've had it for about 7 months . i bought it only because i was desperate for a cheap straightener because my hair is very thick , long , wavy ! i 'm looking for a new straighner right now ... but until then this one is doing just fine . if it works for me , it will work for you !\n",
      "1 : barbie ballet shoes icon doll i was looking round the toysrus website and found this cheap doll ! \" wow \" i said . so i got it and her body is painted on ! which is really cute ! , parents would n't you like to get a toy where you save yourself from picking up another barbie item from the floor ! well , make a cardboard dancefloor and she can do her piroettes happily . her shoes are very pretty ! , pink with laces ! her hair is very good quality and easy to style ! get her !\n",
      "2 : cloud b twilight constellation night light i bought this item because it had good reviews , and looked really cool . it 's a turtle with 3 different colored led lights on the inside that are supposed to project stars in a room or on a ceiling . of the 3 colors green , amber and blue only the green and blue are noticable in pitch black . the amber is almost a waisted option because you ca n't see it . my problem with this item is it only works in pitch black , and barely in that case . the product shots show it sitting on a nursery floor shining up at the ceiling , this is sooooo impossible . the turtle needs to be at least 2 feet from the ceiling in order to see any of the stars . a total disappointment . i returned it .\n",
      "3 : alessi zuppa toscana tuscan white bean soup ( pack of 6 ) this soup taste great . even better if you add the olive oil and grated parm cheese . only takes about 15 mins to make . the package arrived quick . ordered on sunday night , had tuesday morning ( used prime , 2 shipping ) a day early . i will probably order a few more boxes very soon .\n",
      "4 : swedish beauty amaretto tanning lotion advanced dark tanning system with triple bronzer and shimmer i ordered this because i was running low on my current tanning lotion which i love and it smells like skittles , so i read the reviews for this one that was supposed to smell like cherries or almonds and it does not smell like either . it just has a chemical odor and has so much bronzer in it that i really have to make sure to wipe my hands off . i will definitely be ordering some more of my original lotion to replace this nasty stuff .\n",
      "5 : stash green white tea blends , 18 or 20 count tea bags ( pack of 6 ) i 've been tasting along several green tea 's trying to find one that i liked . i was beginning to feel a little like goldilocks . one would be too strong , the other too bland . i think the spearmint in this tea adds an really nice note with the peppermint and lemongrass , making it actually enjoyable rather than a necessary evil . i found the mint to be nicely pronounced , and the lemongrass to be only barely detectable , with a little bit of honey it 's really good . so if you 're looking for a way to incorporate green tea into your daily routine , and like me you like it mildly paired with mint . then give this tea a shot . ( i do agree that maybe you should try with a single box first , so that you 're not stuck with 6 if your palate is more refined than mine )\n",
      "6 : mama mio tummy rub stretch mark butter , 4 oz , say no to stretch marks ! i started with the mama mio oil and loved it so much i had to try the belly butter . it 's wonderful . smells great and absorbs really well . on days when i really want to make my belly soft i use the oil followed by the belly butter . i 've tried several on the market and this is the best . wish it was n't so pricey ... but that 's my only beef with it .\n",
      "7 : tiny love super deluxe lights and music gymini activity gym we gifted this toy to our niece nimisha when she was completing 2 months .. initially she spent only few minutes in this gym .. but as she grows she seems fascinated about the gym and absolutely loves it . she is now 5 months old and she enjoys pulling and kicking at the toys . we like the aspect that there are additional hooks to hang more toys . over all it is a good value for the money .\n",
      "8 : oral b professional care 1000 power toothbrush yes yes yes ! i love this toothbrush ! i will never be able to use a manual toothbrush again . i look forward to that quot fresh from the dentist quot feeling every time i brush my teeth . my wisdom teeth grew in without problems , so i still have them back there and they are the most difficult teeth to brush . my manual toothbrush simply was n't doing the job . if you think about it , the shape of a regular toothbrush just is n't made to get to the back molars very well . now , not only are they getting brushed , they are getting polished ! even the very back back of the teeth themselves thanks to the nice small round shape of the brushhead combined with the fast pulsating action . my gums are healthy and every one of my teeth are white and plaque free , what else can i say ?\n",
      "9 : kick play piano with music , sounds twinkling lights i purchased this toy for my son before he was born and started using it at about 2 months of age . he is now 8 months old and has kicked it vigorously many times and it still works great . i do n't think it is very educational except that he has learned that when he kicks it or touches it ( when i lay it on the floor for him ) it plays sounds and lights up . the tone of the music is soft to the ears , lights up colorfully , and the animal sounds are adorable . you can select several activities by the turn of a knob which is great so that child nor parents will get frusted of the repetiveness . i have bought this piano for several of my friends for thier infants and they love it ! great entertainer for a child .\n",
      "\n",
      "29487\n",
      "0 : omron hem 790it automatic blood pressure monitor with advanced omron health management software so far this machine has worked well and is very simple to use . it is nice to have immediate feedback on the bloodpressure effects of my various exercises , food consumption , and relaxation or stress levels .\n",
      "1 : natural factors whey factors chocolate works well , but there is a lot of dead space in the container when you first open it up . the container comes 3 4 4 5 full and the rest in empty space .\n",
      "2 : clif bar builder 's bar , 2 . 4 ounce bars i love the peanut butter builder 's bars . while amazon is great for so many things , a trip to tj 's is too good to pass up . a little cup of coffee , a sample or two and into the cart with some fresh vegetables and whatever else is irresistible that day . life does n't get much better . if tj 's were n't local ( perish the thought ! ) , i 'd order the bars from amazon . with amazon 's sales volume , 2 day fedex delivery and a sheltered place for the packages when they arrive , freshness has n't been a problem .\n",
      "3 : andis 1875 watt professional ceramic ionic hair dryer i was a little hesitant to purchase since it was rather cheap for a good ionic dryer but it worked great . i have 3c type hair and it dried my hair rather quickly and straight , with minimal frizz but it did die out exactly a year later . so i guess you get what you pay for .... but it was good while it lasted .\n",
      "4 : clif bar energy bars these were cheaper than what i had bought at sam 's and worked very well . they are very convient and i would recommend them to anyone not willing to make their own at a cheaper price because of the convience of having a good product , at a somewhat reasonable price compared to the marketplace . they tasted very good , maybe too good , my grands love them and could consume them at a high rate . then i had to consume them to keep up with their energy . truth is i probably needed them a lot more than they did . it was a good experience and i will buy them again when i do n't have the time to make homemade ones .\n",
      "5 : gillette fusion power cartridges until i tried fusion catridges , i got decent shaves but not great . i was always cutting myself atleast once a week , especially on my chin . now , i get the smooth shaves and i never cut myself . i also think the shaves are closest to the skin that is possible for me . razors today are vastly superior to razors twenty years ago . i grew a beard for two years to avoid shaving . it seems every 2 3 years , a new shaving product comes out that is much better . i think fusion is that product . i like the power option as it seems my shaves are faster but maybe it is psychological . i like shaving now because of fusion .\n",
      "6 : fisher price bright beginnings stacking action blocks we played with these at a friend 's house when our son was about 10 months old . he really enjoyed playing with them then . we bought him his own set for his first birthday . he played with them for a little while , but now , at 18 months , never pulls them out to play with them anymore . we should 've gotten them when he was about 6 months old or so .\n",
      "7 : sony rechargeable battery part npfe1 the replacement battery charged in less time then the oem . excellent value and allowed me to keep my older digital camera . fe1 battery kept 10mp camera fully functionalwhen charged with new digital ac dc charger .\n",
      "8 : boppy nursing pillow with slipcover love this must have if your serious about breast feeding your baby or even bottle feeding too . very usefull but i did have friends who never used theres . its good for baby to use to lay one n when i was preg i loved it soo much ! would recommend !\n",
      "9 : lumiscope stirrup stockings pair these are very comfortable and you can wear any color of socks . the only con is that it needs elastic at the top to keep them up . i do like them very much .\n",
      "\n",
      "69\n",
      "0 : [1, 8, 208, 211, 213, 216, 229, 255, 265, 218, 271, 277, 249, 288, 313, 357]\n",
      "1 : [2, 434, 413, 483, 464, 520, 527]\n",
      "3 : [4, 5, 13, 15, 17, 21, 28, 30, 34, 35, 50, 51, 53, 85, 111, 120, 147]\n",
      "4 : [7, 19, 70, 174, 176, 183, 188, 210, 238, 294, 375, 392, 407, 433, 435]\n",
      "5 : [6, 57, 97, 133, 228, 331, 385]\n",
      "8 : [9, 206, 235, 270, 285, 308, 327, 391, 405, 410, 514]\n",
      "10 : [11, 44, 54, 60, 64, 220]\n",
      "11 : [12, 69, 45, 109, 205, 67, 419]\n",
      "13 : [14, 20, 37, 122, 150, 204, 378, 401, 477, 506, 517]\n",
      "15 : [16, 56, 144, 166]\n",
      "\n",
      "531\n",
      "grocery_gourmet_food : ['snacks', 'condiments', 'beverages', 'specialty_foods', 'spices', 'cooking_oils', 'baking_ingredients', 'gourmet_chocolates', 'artisanal_cheeses', 'organic_foods']\n",
      "meat_poultry : ['butcher', 'cuts', 'marination', 'grilling', 'roasting', 'seasoning', 'halal', 'organic', 'deli', 'marbling']\n",
      "jerky : ['beef', 'turkey', 'chicken', 'venison', 'buffalo', 'kangaroo', 'elk', 'ostrich', 'bison', 'spicy']\n",
      "toys_games : ['board_games', 'puzzles', 'action_figures', 'building_blocks', 'dolls', 'outdoor_toys', 'educational_toys', 'card_games', 'remote_control_toys', 'plush_toys']\n",
      "games : ['board_games', 'card_games', 'tabletop_games', 'party_games', 'roleplaying_games', 'video_games', 'strategy_games', 'family_games', 'word_games', 'dice_games']\n",
      "puzzles : ['jigsaw_puzzles', 'brain_teasers', 'puzzle_accessories', 'puzzle_storage', 'puzzle_mats', 'puzzle_glue', 'puzzle_organizers', 'puzzle_books', 'puzzle_magazines', 'puzzle_competitions']\n",
      "jigsaw_puzzles : ['interlocking_pieces', 'puzzle_boards', 'puzzle_glue', 'puzzle_storage', 'puzzle_frames', 'puzzle_rolls', 'puzzle_organizers', 'puzzle_tables', 'puzzle_sleeves', 'puzzle_sorting_trays']\n",
      "board_games : ['board_game_accessories', 'strategy_games', 'cooperative_games', 'family_games', 'classic_board_games', 'party_games', 'educational_board_games', 'roleplaying_games', 'abstract_strategy_games', 'word_games']\n",
      "beverages : ['coffee', 'tea', 'energy_drinks', 'soft_drinks', 'bottled_water', 'juices', 'sports_drinks', 'smoothies', 'iced_tea', 'coconut_water']\n",
      "juices : ['fruit_juices', 'fresh_squeezed', 'coldpressed', 'organic', 'juice_blends', 'juice_cleanse', 'citrus_juices', 'juice_boxes', 'juice_bars', 'juicing_machines']\n"
     ]
    }
   ],
   "source": [
    "# --- Load ---\n",
    "\n",
    "\"\"\" \n",
    "1. Training corpus: 29,487 product reviews without class labels.\n",
    "2. Classes: 531 product categories.\n",
    "3. Class hierarchy: A taxonomy file that defines parentâ€“child relationships among classes (each line represents one relation).\n",
    "4. Class-related keywords: A list of keywords associated with each product class.\n",
    "5. Test corpus: 19,658 product reviews for evaluation.\n",
    "\"\"\"\n",
    "\n",
    "def load_corpus(path):\n",
    "    \"\"\"Load test corpus into {id: text} dictionary.\"\"\"\n",
    "    id2text = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\", 1)\n",
    "            if len(parts) == 2:\n",
    "                id, text = parts\n",
    "                id2text[id] = text\n",
    "    return id2text\n",
    "\n",
    "def load_multilabel(path):\n",
    "    \"\"\"Load multi-label data into {id: [labels]} dictionary.\"\"\"\n",
    "    id2labels = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) == 2:\n",
    "                pid, label = parts\n",
    "                pid = int(pid)\n",
    "                label = int(label)\n",
    "\n",
    "                if pid not in id2labels:\n",
    "                    id2labels[pid] = []\n",
    "\n",
    "                id2labels[pid].append(label)\n",
    "    return id2labels\n",
    "\n",
    "def load_class_keywords(path):\n",
    "    \"\"\"Load class keywords into {class_name: [keywords]} dictionary.\"\"\"\n",
    "    class2keywords = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if \":\" not in line:\n",
    "                continue\n",
    "            classname, keywords = line.strip().split(\":\", 1)\n",
    "            keyword_list = [kw.strip() for kw in keywords.split(\",\") if kw.strip()]\n",
    "            class2keywords[classname] = keyword_list\n",
    "    return class2keywords\n",
    "\n",
    "id2text_test = load_corpus(TEST_CORPUS_PATH)\n",
    "id_list_test = list(id2text_test.keys())\n",
    "\n",
    "id2text_train = load_corpus(TRAIN_CORPUS_PATH)\n",
    "id_list_train = list(id2text_train.keys())\n",
    "\n",
    "id2class = load_corpus(CLASS_PATH)\n",
    "class2hierarchy = load_multilabel(CLASS_HIERARCHY_PATH)\n",
    "class2related = load_class_keywords(CLASS_RELATED_PATH)\n",
    "\n",
    "# ======== Print ===========\n",
    "\n",
    "print(len(id2class)) \n",
    "for i in range(10):\n",
    "    print(i, \":\", id2class[str(i)])\n",
    "\n",
    "print()\n",
    "\n",
    "print(len(id2text_test)) \n",
    "for i, (id, text) in enumerate(id2text_test.items()):\n",
    "    if i >= 10: \n",
    "        break\n",
    "    print(id, \":\", text)\n",
    "\n",
    "print()\n",
    "\n",
    "print(len(id2text_train)) \n",
    "for i, (id, text) in enumerate(id2text_train.items()):\n",
    "    if i >= 10: \n",
    "        break\n",
    "    print(id, \":\", text)\n",
    "\n",
    "print()\n",
    "print(len(class2hierarchy)) \n",
    "for i, (id, node) in enumerate(class2hierarchy.items()):\n",
    "    if i >= 10: \n",
    "        break\n",
    "    print(id, \":\", node)\n",
    "\n",
    "\n",
    "print()\n",
    "print(len(class2related)) \n",
    "for i, (classp, text) in enumerate(class2related.items()):\n",
    "    if i >= 10: \n",
    "        break\n",
    "    print(classp, \":\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9221c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb train: 29487\n",
      "Nb test : 19658\n",
      "Nb classes: 531\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"[>&]\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9 ]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "label_texts = []\n",
    "for cid in range(NUM_CLASSES):\n",
    "    cid_str = str(cid)\n",
    "    class_name = id2class[cid_str]              \n",
    "    class_name_clean = preprocess_text(class_name)\n",
    "    \n",
    "    keywords = class2related.get(class_name, [])  \n",
    "    keywords_clean = \" \".join(preprocess_text(kw) for kw in keywords)\n",
    "    \n",
    "    full_label_text = (class_name_clean + \" \" + keywords_clean).strip()\n",
    "    label_texts.append(full_label_text)\n",
    "\n",
    "\n",
    "train_ids = list(id2text_train.keys())\n",
    "train_texts = [preprocess_text(id2text_train[pid]) for pid in train_ids]\n",
    "\n",
    "test_ids = list(id2text_test.keys())\n",
    "test_texts = [preprocess_text(id2text_test[pid]) for pid in test_ids]\n",
    "\n",
    "print(\"Nb train:\", len(train_texts))\n",
    "print(\"Nb test :\", len(test_texts))\n",
    "print(\"Nb classes:\", len(label_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf92b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shapes:\n",
      "  train: (29487, 46599)\n",
      "  label: (531, 46599)\n",
      "Lexical similarity (train): (29487, 531)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "all_texts = train_texts + label_texts\n",
    "tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "\n",
    "n_train = len(train_texts)\n",
    "n_labels = len(label_texts)\n",
    "\n",
    "train_tfidf = tfidf_matrix[:n_train]\n",
    "label_tfidf = tfidf_matrix[n_train:]\n",
    "\n",
    "print(\"TF-IDF shapes:\")\n",
    "print(\"  train:\", train_tfidf.shape)\n",
    "print(\"  label:\", label_tfidf.shape)\n",
    "\n",
    "lex_sim_train = cosine_similarity(train_tfidf, label_tfidf)\n",
    "print(\"Lexical similarity (train):\", lex_sim_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648e1010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#  SEMANTIC EMBEDDINGS PART\\n\\nfrom sentence_transformers import SentenceTransformer\\nfrom sklearn.metrics.pairwise import cosine_similarity\\nimport torch\\nimport numpy as np\\nfrom tqdm import tqdm\\n\\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\\n\\nmodel_name = \"all-mpnet-base-v2\"\\nmodel = SentenceTransformer(model_name, device=device)\\n\\n# --- Encode class texts (531 classes, enriched with keywords)\\nprint(\"\\nðŸ”¹ Encoding class embeddings...\")\\nlabel_emb = model.encode(label_texts, convert_to_tensor=True, show_progress_bar=True, batch_size=64)\\n\\n# --- Encode training product texts\\nprint(\"ðŸ”¹ Encoding train product embeddings...\")\\ntrain_emb = model.encode(train_texts, convert_to_tensor=True, show_progress_bar=True, batch_size=64)\\n\\nprint(\"\\nShapes:\")\\nprint(f\"  Train embeddings: {train_emb.shape}\")\\nprint(f\"  Label embeddings: {label_emb.shape}\")\\n\\n# --- Compute cosine similarities (semantic similarity)\\nprint(\"\\nðŸ”¹ Computing cosine similarities...\")\\ntrain_np = train_emb.cpu().numpy()\\nlabel_np = label_emb.cpu().numpy()\\n\\nbert_sim_train = cosine_similarity(train_np, label_np)\\n\\nprint(f\"BERT similarity (train): {bert_sim_train.shape}\")\\n\\n# --- Save for reuse\\ntorch.save({\\n    \"train_emb\": train_emb,\\n    \"label_emb\": label_emb,\\n    \"bert_sim_train\": torch.tensor(bert_sim_train),\\n}, \"Amazon_products/semantic_embeddings.pt\")\\n\\nprint(\"\\nSemantic embeddings and similarities saved to Amazon_products/semantic_embeddings.pt\")'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#  SEMANTIC EMBEDDINGS PART\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"all-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "# --- Encode class texts (531 classes, enriched with keywords)\n",
    "label_emb = model.encode(label_texts, convert_to_tensor=True, show_progress_bar=True, batch_size=64)\n",
    "\n",
    "# --- Encode training product texts\n",
    "train_emb = model.encode(train_texts, convert_to_tensor=True, show_progress_bar=True, batch_size=64)\n",
    "\n",
    "print(\"\\nShapes:\")\n",
    "print(f\"  Train embeddings: {train_emb.shape}\")\n",
    "print(f\"  Label embeddings: {label_emb.shape}\")\n",
    "\n",
    "# --- Compute cosine similarities (semantic similarity)\n",
    "train_np = train_emb.cpu().numpy()\n",
    "label_np = label_emb.cpu().numpy()\n",
    "\n",
    "bert_sim_train = cosine_similarity(train_np, label_np)\n",
    "\n",
    "print(f\"BERT similarity (train): {bert_sim_train.shape}\")\n",
    "\n",
    "# --- Save for reuse\n",
    "torch.save({\n",
    "    \"train_emb\": train_emb,\n",
    "    \"label_emb\": label_emb,\n",
    "    \"bert_sim_train\": torch.tensor(bert_sim_train),\n",
    "}, \"Amazon_products/semantic_embeddings.pt\")\n",
    "\n",
    "print(\"\\nSemantic embeddings and similarities saved to Amazon_products/semantic_embeddings.pt\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4a42a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def hierarchy_consistency(silver, hierarchy):\n",
    "    ok = total = 0\n",
    "    for labels in silver.values():\n",
    "        L = set(labels)\n",
    "        for parent, children in hierarchy.items():\n",
    "            parent = int(parent)\n",
    "            for child in children:\n",
    "                child = int(child)\n",
    "                if child in L:\n",
    "                    total += 1\n",
    "                    if parent in L:\n",
    "                        ok += 1\n",
    "    return ok / total if total > 0 else 0\n",
    "\n",
    "\n",
    "def analyze_coverage(silver, name, n_classes=531):\n",
    "    all_labels = [c for labels in silver.values() for c in labels]\n",
    "    unique = len(set(all_labels))\n",
    "    counter = Counter(all_labels)\n",
    "    top5 = counter.most_common(5)\n",
    "\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Coverage: {unique}/{n_classes} ({unique/n_classes*100:.1f}%)\")\n",
    "    print(f\"  Top-5 most frequent classes:\")\n",
    "    for cls, count in top5:\n",
    "        print(f\"    Class {cls}: {count} times ({count/len(silver)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b334f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final similarity matrix: (29487, 531)\n",
      "\n",
      "Without hierarchy : 0.1062\n",
      "\n",
      "Baseline Train (no hierarchy):\n",
      "  Coverage: 530/531 (99.8%)\n",
      "  Top-5 most frequent classes:\n",
      "    Class 148: 1495 times (5.1%)\n",
      "    Class 43: 1256 times (4.3%)\n",
      "    Class 220: 1170 times (4.0%)\n",
      "    Class 164: 1087 times (3.7%)\n",
      "    Class 25: 984 times (3.3%)\n",
      "\n",
      "[Doc 0]\n",
      "Text: omron hem 790it automatic blood pressure monitor with advanced omron health management software so far this machine has worked well and is very simple to use . it is nice to have immediate feedback on...\n",
      "   health_monitors                     score=0.3620\n",
      "   automatic_feeders                   score=0.2359\n",
      "   health_personal_care                score=0.2321\n",
      "\n",
      "[Doc 1]\n",
      "Text: natural factors whey factors chocolate works well , but there is a lot of dead space in the container when you first open it up . the container comes 3 4 4 5 full and the rest in empty space ....\n",
      "   chocolate                           score=0.3875\n",
      "   chocolate_bars                      score=0.3821\n",
      "   chocolate_covered_fruit             score=0.3694\n",
      "\n",
      "[Doc 2]\n",
      "Text: clif bar builder 's bar , 2 . 4 ounce bars i love the peanut butter builder 's bars . while amazon is great for so many things , a trip to tj 's is too good to pass up . a little cup of coffee , a sam...\n",
      "   granola_bars                        score=0.4032\n",
      "   bars                                score=0.3882\n",
      "   breakfast_cereal_bars               score=0.3724\n",
      "\n",
      "[Doc 3]\n",
      "Text: andis 1875 watt professional ceramic ionic hair dryer i was a little hesitant to purchase since it was rather cheap for a good ionic dryer but it worked great . i have 3c type hair and it dried my hai...\n",
      "   styling_tools                       score=0.3110\n",
      "   hair_care                           score=0.3098\n",
      "   styling_products                    score=0.2982\n",
      "\n",
      "[Doc 4]\n",
      "Text: clif bar energy bars these were cheaper than what i had bought at sam 's and worked very well . they are very convient and i would recommend them to anyone not willing to make their own at a cheaper p...\n",
      "   granola_bars                        score=0.3789\n",
      "   nutrition_bars_drinks               score=0.3731\n",
      "   bars                                score=0.3692\n"
     ]
    }
   ],
   "source": [
    "data_sem = torch.load(\"Embeddings/semantic_embeddings.pt\")\n",
    "bert_sim_train = data_sem[\"bert_sim_train\"].numpy()\n",
    "\n",
    "alpha = 0.4\n",
    "final_sim = alpha * lex_sim_train + (1 - alpha) * bert_sim_train\n",
    "print(f\"Final similarity matrix: {final_sim.shape}\")\n",
    "\n",
    "TOP_K = 3\n",
    "silver_baseline = {\n",
    "    pid: np.argsort(-final_sim[i])[:TOP_K].tolist()\n",
    "    for i, pid in enumerate(id_list_train)\n",
    "}\n",
    "\n",
    "train_consistency_no = hierarchy_consistency(silver_baseline, class2hierarchy)\n",
    "print(f\"\\nWithout hierarchy : {train_consistency_no:.4f}\")\n",
    "analyze_coverage(silver_baseline, \"Baseline Train (no hierarchy)\")\n",
    "\n",
    "id2class_name = {int(cid): cname.strip() for cid, cname in id2class.items()}\n",
    "for i, pid in enumerate(list(id_list_train)[:5]):\n",
    "    print(f\"\\n[Doc {pid}]\")\n",
    "    print(\"Text:\", id2text_train[pid][:200].replace(\"\\n\", \" \") + \"...\")\n",
    "    for cls_id in silver_baseline[pid]:\n",
    "        print(f\"   {id2class_name.get(cls_id, f'Class_{cls_id}'):<35} score={final_sim[i, cls_id]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccc0245f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generating hierarchical silver labels ===\n",
      "  Baseline (no hierarchy):  0.1062\n",
      "  With hierarchy:           0.5820\n",
      "\n",
      "Baseline Train (no hierarchy):\n",
      "  Coverage: 518/531 (97.6%)\n",
      "  Top-5 most frequent classes:\n",
      "    Class 3: 3543 times (12.0%)\n",
      "    Class 21: 2994 times (10.2%)\n",
      "    Class 23: 2941 times (10.0%)\n",
      "    Class 10: 2862 times (9.7%)\n",
      "    Class 24: 2850 times (9.7%)\n",
      "\n",
      "[Doc 0]\n",
      "Text: omron hem 790it automatic blood pressure monitor with advanced omron health management software so far this machine has worked well and is very simple to use . it is nice to have immediate feedback on...\n",
      "   medical_supplies_equipment          score=0.1758\n",
      "   health_monitors                     score=0.3620\n",
      "   health_personal_care                score=0.2321\n",
      "\n",
      "[Doc 1]\n",
      "Text: natural factors whey factors chocolate works well , but there is a lot of dead space in the container when you first open it up . the container comes 3 4 4 5 full and the rest in empty space ....\n",
      "   cooking_baking_supplies             score=0.1378\n",
      "   chocolate                           score=0.3875\n",
      "   candy_chocolate                     score=0.3253\n",
      "\n",
      "[Doc 2]\n",
      "Text: clif bar builder 's bar , 2 . 4 ounce bars i love the peanut butter builder 's bars . while amazon is great for so many things , a trip to tj 's is too good to pass up . a little cup of coffee , a sam...\n",
      "   snack_food                          score=0.3191\n",
      "   granola_bars                        score=0.4032\n",
      "   candy_chocolate                     score=0.2728\n",
      "\n",
      "[Doc 3]\n",
      "Text: andis 1875 watt professional ceramic ionic hair dryer i was a little hesitant to purchase since it was rather cheap for a good ionic dryer but it worked great . i have 3c type hair and it dried my hai...\n",
      "   beauty                              score=0.1633\n",
      "   hair_care                           score=0.3098\n",
      "   styling_tools                       score=0.3110\n",
      "\n",
      "[Doc 4]\n",
      "Text: clif bar energy bars these were cheaper than what i had bought at sam 's and worked very well . they are very convient and i would recommend them to anyone not willing to make their own at a cheaper p...\n",
      "   snack_food                          score=0.3335\n",
      "   granola_bars                        score=0.3789\n",
      "   nutrition_wellness                  score=0.1736\n"
     ]
    }
   ],
   "source": [
    "def propagate_hierarchy_to_embeddings(label_emb, hierarchy, alpha_prop=0.25):\n",
    "    enhanced = label_emb.clone()\n",
    "    for parent, children in hierarchy.items():\n",
    "        parent = int(parent)\n",
    "        if children:\n",
    "            child_embs = label_emb[[int(c) for c in children]]\n",
    "            enhanced[parent] = (1 - alpha_prop) * label_emb[parent] + alpha_prop * child_embs.mean(0)\n",
    "    return enhanced\n",
    "\n",
    "\n",
    "def enforce_hierarchy_constraints(scores, hierarchy, top_k=3, parent_boost=0.15):\n",
    "    scores = scores.copy()\n",
    "    for parent, children in hierarchy.items():\n",
    "        parent = int(parent)\n",
    "        if children:\n",
    "            max_child_score = max(scores[int(c)] for c in children)\n",
    "            scores[parent] = max(scores[parent], max_child_score * (1 - parent_boost))\n",
    "    candidates = np.argsort(-scores)[:top_k * 3]\n",
    "    selected, added = [], set()\n",
    "    for c in candidates:\n",
    "        if len(selected) >= top_k: break\n",
    "        for parent, children in hierarchy.items():\n",
    "            parent = int(parent)\n",
    "            if c in [int(x) for x in children]:\n",
    "                added.add(parent)\n",
    "        while added and len(selected) < top_k:\n",
    "            p = max(added, key=lambda x: scores[x])\n",
    "            added.remove(p)\n",
    "            if p not in selected: selected.append(p)\n",
    "        if len(selected) < top_k and c not in selected:\n",
    "            selected.append(c)\n",
    "    return selected[:top_k]\n",
    "\n",
    "\n",
    "print(\"\\n=== Generating hierarchical silver labels ===\")\n",
    "label_emb_enriched = propagate_hierarchy_to_embeddings(\n",
    "    data_sem[\"label_emb\"], class2hierarchy, alpha_prop=0.25\n",
    ")\n",
    "\n",
    "bert_sim_enriched = cosine_similarity(\n",
    "    data_sem[\"train_emb\"].cpu().numpy(),\n",
    "    label_emb_enriched.cpu().numpy()\n",
    ")\n",
    "\n",
    "final_sim_enriched = alpha * lex_sim_train + (1 - alpha) * bert_sim_enriched\n",
    "\n",
    "silver_hierarchy = {\n",
    "    pid: enforce_hierarchy_constraints(final_sim_enriched[i], class2hierarchy, TOP_K, 0.15)\n",
    "    for i, pid in enumerate(id_list_train)\n",
    "}\n",
    "\n",
    "train_consistency_hier = hierarchy_consistency(silver_hierarchy, class2hierarchy)\n",
    "\n",
    "print(f\"  Baseline (no hierarchy):  {train_consistency_no:.4f}\")\n",
    "print(f\"  With hierarchy:           {train_consistency_hier:.4f}\")\n",
    "\n",
    "\n",
    "analyze_coverage(silver_hierarchy, \"Baseline Train (no hierarchy)\")\n",
    "\n",
    "id2class_name = {int(cid): cname.strip() for cid, cname in id2class.items()}\n",
    "for i, pid in enumerate(list(id_list_train)[:5]):\n",
    "    print(f\"\\n[Doc {pid}]\")\n",
    "    print(\"Text:\", id2text_train[pid][:200].replace(\"\\n\", \" \") + \"...\")\n",
    "    for cls_id in silver_hierarchy[pid]:\n",
    "        print(f\"   {id2class_name.get(cls_id, f'Class_{cls_id}'):<35} score={final_sim[i, cls_id]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8136c9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Silver labels saved to: Silver/hier.json\n",
      "\n",
      "Silver labels saved to: Silver/base.json\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "\n",
    "def to_json_serializable(d):\n",
    "    \"\"\"Convertit les types NumPy â†’ int/float natifs pour JSON.\"\"\"\n",
    "    return {str(k): [int(x) for x in v] for k, v in d.items()}\n",
    "\n",
    "os.makedirs(\"Silver\", exist_ok=True)\n",
    "\n",
    "# --- Save hierarchical labels ---\n",
    "output_path = \"Silver/hier.json\"\n",
    "results_hier = {\"silver_hierarchy\": to_json_serializable(silver_hierarchy)}\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(results_hier, f, indent=2)\n",
    "\n",
    "print(f\"\\nSilver labels saved to: {output_path}\")\n",
    "\n",
    "# --- Save baseline labels ---\n",
    "output_path = \"Silver/base.json\"\n",
    "results_base = {\"silver_baseline\": to_json_serializable(silver_baseline)}\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(results_base, f, indent=2)\n",
    "\n",
    "print(f\"\\nSilver labels saved to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
