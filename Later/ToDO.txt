AWS Ressources -> 90%

Build a classifier

bash

tasks : Silver label generation (taxonomy + keywords)
Transformer-based classifier training
Optional self-training and hierarchy refinement
Final Kaggle prediction file generation

TaxoClass original:
[Entailment ‚Üí Core class mining ‚Üí Dual encoder + BCE loss ‚Üí Self-training]
Toi:
[Embeddings ‚Üí Silver labels ‚Üí MLP / GNN sur labels faibles]

Unlabeled

1Ô∏è‚É£ Load raw + labeled + silver data
2Ô∏è‚É£ Preprocessing / encoding
3Ô∏è‚É£ Build model (student)
4Ô∏è‚É£ Train student + teacher (EMA)
5Ô∏è‚É£ Evaluate on val set (example F1)
6Ô∏è‚É£ Generate predictions on test set
7Ô∏è‚É£ Format submission

# BERT fine-tuning

""" Our TaxoClass framework consists of four major
 steps: (1) document-class similarity calculation, (2)
 document core class mining, (3) core class guided
 classifier training, and (4) multi-label self-training.
 Fig. 2 shows our framework overview and below
 sections discuss each step in more details.

Step Purpose	Requires LLM?	Paper Section
(A) Enrich class information	Generate keywords for each class	‚úÖ Yes (few prompts)	Sec. 3.1 improvement
(B) Get more accurate labels for hard cases	Filter candidate labels	‚úÖ Yes but few calls	Sec. 3.4 (Self-training help)
(C) Optional iterative correction	Improve hard samples gradually	‚úÖ Yes (but limited)	Sec. 3.3‚Äì3.4

1. Silver label generation: Explain the methodology used to generate silver labels De
scribe your design choices, heuristics, and the use of large language models (LLMs), if
 any. Provide reasoning for how your approach maintains label reliability.
 
 2. Training process: Describe how you trained your model(s), including learning objec
tives (e.g., loss functions) and advanced strategies applied (e.g., self-training, regulariza
tion, data augmentation). Provide reasoning for how your approach improves learning
 effectiveness.

 3. Model and Prediction Method: Clearly describe how you make predictions ‚Äî which
 models were used (e.g., pretrained encoders, LLMs, classifiers) and how they were com
bined or integrated to produce final predictions, if applicable.

 4. Experimental results: Summarize your experimental results in a table that includes
 both your best-performing result and other meaningful attempts or ablation variants you
 tried. You are encouraged to use techniques covered in class, but you are not limited
 to them. We expect your results table to include a comparison of various techniques
 introduced in class, including at least self-training and GNN-based approaches. For
 reference, see Table 2 in the reference paper

üí° Self-training (si tu le fais)
üí° Prediction finale

propagation of information over graph for labels and for features p26
GNN / GCN
"""

A. Filtrage des silver labels	Nettoyer les pseudo-labels incertains	~600	C‚Äôest ici que le LLM t‚Äôapporte le plus de gain direct
B. V√©rification des pr√©dictions finales (test)	Ajuster les labels incoh√©rents apr√®s ton mod√®le	~300	Am√©liore ton F1 Kaggle sans toucher au training
C. Analyse d‚Äôerreurs	Comprendre les confusions du mod√®le	~100	Pour am√©liorer ta prochaine version

llm plus tard