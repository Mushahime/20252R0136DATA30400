{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8cfbf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Device: cuda\n",
      "Train IDs: 29487 | Test IDs: 19658\n",
      "\n",
      "üß† Loading X_all.pt ...\n",
      "‚úì X_train: torch.Size([29487, 768]), X_test: torch.Size([19658, 768])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIGURATION\n",
    "# ==========================================================\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üîß Device: {device}\")\n",
    "\n",
    "# Paths\n",
    "ROOT = Path(\"Amazon_products\")\n",
    "TRAIN_CORPUS_PATH = ROOT / \"train\" / \"train_corpus.txt\"\n",
    "TEST_CORPUS_PATH  = ROOT / \"test\" / \"test_corpus.txt\"\n",
    "CLASS_PATH        = ROOT / \"classes.txt\"\n",
    "\n",
    "EMB_DIR      = Path(\"Embeddings\")\n",
    "X_ALL_PATH   = EMB_DIR / \"X_train_test_mpn.pt\"        # Train + Test embeddings\n",
    "LABEL_EMB_PATH = EMB_DIR / \"labels_hierarchical_new_mpn.pt\"\n",
    "\n",
    "MODEL_SAVE = Path(\"Models\")\n",
    "MODEL_SAVE.mkdir(exist_ok=True)\n",
    "MODEL_PATH = MODEL_SAVE / \"silver_classifier.pt\"\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD IDS\n",
    "# ==========================================================\n",
    "def load_ids(path):\n",
    "    ids = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            pid, _ = line.strip().split(\"\\t\", 1)\n",
    "            ids.append(int(pid))\n",
    "    return ids\n",
    "\n",
    "train_ids = load_ids(TRAIN_CORPUS_PATH)\n",
    "test_ids  = load_ids(TEST_CORPUS_PATH)\n",
    "n_train = len(train_ids)\n",
    "n_test = len(test_ids)\n",
    "\n",
    "print(f\"Train IDs: {n_train} | Test IDs: {n_test}\")\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD SILVER LABELS\n",
    "# ==========================================================\n",
    "with open(\"Silver/silver_train_new_mpn.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "silver_labels = {int(pid): data[\"labels\"] for pid, data in raw.items()}\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD X_all ‚Üí split into X_train + X_test\n",
    "# ==========================================================\n",
    "print(\"\\nüß† Loading X_all.pt ...\")\n",
    "\n",
    "data = torch.load(X_ALL_PATH, weights_only=False)\n",
    "\n",
    "# ensure tensor\n",
    "if isinstance(data, np.ndarray):\n",
    "    data = torch.from_numpy(data)\n",
    "elif isinstance(data, list):\n",
    "    data = torch.stack(data)\n",
    "\n",
    "X_all = data.float().to(device)\n",
    "assert X_all.shape[0] == n_train + n_test, \"Bad size\"\n",
    "\n",
    "X_train = X_all[:n_train]\n",
    "X_test  = X_all[n_train:]\n",
    "print(f\"‚úì X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD CLASS NAMES\n",
    "# ==========================================================\n",
    "classes = {}\n",
    "with open(CLASS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        cid, cname = line.strip().split(\"\\t\")\n",
    "        classes[int(cid)] = cname\n",
    "\n",
    "n_classes = len(classes)\n",
    "\n",
    "pid2idx = {pid: i for i, pid in enumerate(train_ids)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d97c569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, pids, labels_dict):\n",
    "        self.pids = pids\n",
    "        self.labels = labels_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pid = self.pids[idx]\n",
    "        emb = X_train[pid2idx[pid]]\n",
    "\n",
    "        y = torch.zeros(n_classes)\n",
    "        for c in self.labels[pid]:\n",
    "            if 0 <= c < n_classes:\n",
    "                y[c] = 1.0\n",
    "\n",
    "        return {\"X\": emb, \"y\": y}\n",
    "\n",
    "# TRAIN / VAL splits\n",
    "train_p, val_p = train_test_split(list(silver_labels.keys()),\n",
    "                                  test_size=0.2,\n",
    "                                  random_state=42)\n",
    "\n",
    "train_dataset = MultiLabelDataset(train_p, silver_labels)\n",
    "val_dataset   = MultiLabelDataset(val_p,   silver_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f453b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(512, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.drop(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "model = Classifier(X_train.size(1), n_classes).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c66208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, thr=0.25):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            X = batch[\"X\"]\n",
    "            y = batch[\"y\"].numpy()\n",
    "\n",
    "            prob = torch.sigmoid(model(X)).cpu().numpy()\n",
    "            pred = (prob > thr).astype(int)\n",
    "\n",
    "            preds.extend(pred)\n",
    "            labels.extend(y)\n",
    "\n",
    "    f1s = f1_score(labels, preds, average=\"samples\")\n",
    "    f1m = f1_score(labels, preds, average=\"macro\")\n",
    "    return f1s, f1m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dca9836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 186.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss=0.0694 | F1=0.0108\n",
      "New best model saved (0.0108)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 200.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] loss=0.0157 | F1=0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 202.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] loss=0.0123 | F1=0.0144\n",
      "New best model saved (0.0144)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:02<00:00, 178.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] loss=0.0106 | F1=0.1179\n",
      "New best model saved (0.1179)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:02<00:00, 171.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] loss=0.0094 | F1=0.2901\n",
      "New best model saved (0.2901)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 192.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] loss=0.0086 | F1=0.3166\n",
      "New best model saved (0.3166)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 193.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] loss=0.0079 | F1=0.3214\n",
      "New best model saved (0.3214)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 191.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] loss=0.0074 | F1=0.3295\n",
      "New best model saved (0.3295)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 219.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] loss=0.0069 | F1=0.3351\n",
      "New best model saved (0.3351)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 185.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] loss=0.0065 | F1=0.3408\n",
      "New best model saved (0.3408)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 241.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] loss=0.0062 | F1=0.3461\n",
      "New best model saved (0.3461)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 224.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] loss=0.0059 | F1=0.3498\n",
      "New best model saved (0.3498)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 229.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] loss=0.0056 | F1=0.3524\n",
      "New best model saved (0.3524)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 218.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] loss=0.0054 | F1=0.3580\n",
      "New best model saved (0.3580)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 207.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] loss=0.0051 | F1=0.3645\n",
      "New best model saved (0.3645)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 209.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] loss=0.0049 | F1=0.3725\n",
      "New best model saved (0.3725)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 185.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] loss=0.0047 | F1=0.3759\n",
      "New best model saved (0.3759)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 207.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] loss=0.0046 | F1=0.3841\n",
      "New best model saved (0.3841)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 185.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] loss=0.0044 | F1=0.3899\n",
      "New best model saved (0.3899)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 199.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] loss=0.0042 | F1=0.3932\n",
      "New best model saved (0.3932)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:02<00:00, 182.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] loss=0.0040 | F1=0.3976\n",
      "New best model saved (0.3976)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 211.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] loss=0.0039 | F1=0.3994\n",
      "New best model saved (0.3994)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 227.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] loss=0.0038 | F1=0.3980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 213.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] loss=0.0037 | F1=0.3861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 197.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25] loss=0.0035 | F1=0.3675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 217.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26] loss=0.0034 | F1=0.3348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 369/369 [00:01<00:00, 210.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27] loss=0.0033 | F1=0.2957\n",
      "\n",
      "Early stopping triggered!\n",
      "\n",
      "Best validation F1 = 0.3994\n",
      "Model saved at: Models\\silver_classifier.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"\\nüöÄ Training...\")\n",
    "\n",
    "epochs = 100\n",
    "patience = 5\n",
    "wait = 0\n",
    "\n",
    "best_f1 = 0\n",
    "best_state = None\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-2\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=epochs,\n",
    "    eta_min=5e-6\n",
    ")\n",
    "\n",
    "\n",
    "teacher = copy.deepcopy(model)\n",
    "for p in teacher.parameters():\n",
    "    p.requires_grad = False  # teacher = no grad\n",
    "\n",
    "alpha_ema = 0.995\n",
    "\n",
    "def ema_update(teacher, student, alpha):\n",
    "    \"\"\"teacher = alpha*teacher + (1-alpha)*student\"\"\"\n",
    "    for p_t, p_s in zip(teacher.parameters(), student.parameters()):\n",
    "        p_t.data.mul_(alpha).add_(p_s.data, alpha=1 - alpha)\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
    "        X = batch[\"X\"].to(device)\n",
    "        y = batch[\"y\"].to(device)\n",
    "\n",
    "        logits = model(X)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # EMA update\n",
    "        ema_update(teacher, model, alpha_ema)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    teacher.eval()\n",
    "    f1s, f1m = evaluate(teacher, val_loader)\n",
    "\n",
    "    print(f\"[Epoch {epoch}] loss={total_loss/len(train_loader):.4f} | F1={f1s:.4f}\")\n",
    "\n",
    "    if f1s > best_f1:\n",
    "        best_f1 = f1s\n",
    "        wait = 0\n",
    "        best_state = copy.deepcopy(teacher.state_dict())\n",
    "        torch.save(best_state, MODEL_PATH)\n",
    "        print(f\"New best model saved ({best_f1:.4f})\")\n",
    "\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"\\nEarly stopping triggered!\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nBest validation F1 = {best_f1:.4f}\")\n",
    "print(f\"Model saved at: {MODEL_PATH}\")\n",
    "\n",
    "teacher.load_state_dict(best_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31708868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Generating submission...\n",
      "Loaded test IDs: 19658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 308/308 [00:00<00:00, 679.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Submission saved ‚Üí Submission\\submission_mlp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"\\nüìù Generating submission...\")\n",
    "\n",
    "test_ids = []\n",
    "with open(TEST_CORPUS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        pid, _ = line.strip().split(\"\\t\", 1)\n",
    "        test_ids.append(int(pid))\n",
    "\n",
    "print(f\"Loaded test IDs: {len(test_ids)}\")\n",
    "\n",
    "X_all = torch.load(X_ALL_PATH, weights_only=False)\n",
    "\n",
    "if isinstance(X_all, np.ndarray):\n",
    "    X_all = torch.from_numpy(X_all)\n",
    "elif isinstance(X_all, list):\n",
    "    X_all = torch.stack(X_all)\n",
    "\n",
    "X_all = X_all.float()\n",
    "\n",
    "n_test = len(test_ids)\n",
    "X_test = X_all[-n_test:]\n",
    "\n",
    "# ==========================================================\n",
    "# LOAD MODEL\n",
    "# ==========================================================\n",
    "\n",
    "teacher.eval()\n",
    "X_test = X_test.to(device)\n",
    "\n",
    "# ==========================================================\n",
    "# SELECTION : top-2 / top-3 like self-training\n",
    "# ==========================================================\n",
    "def select_k(prob, min_k=2, max_k=3):\n",
    "    idx = np.argsort(prob)[::-1]     # tri d√©croissant\n",
    "    top3 = idx[:max_k]\n",
    "\n",
    "    # Si le 3eme est trop faible ‚Üí garder seulement 2\n",
    "    if prob[top3[2]] < 0.25 * prob[top3[1]]:\n",
    "        return top3[:2]\n",
    "\n",
    "    return top3\n",
    "\n",
    "\n",
    "# PREDICTION\n",
    "preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for start in tqdm(range(0, len(X_test), 64)):\n",
    "        batch = X_test[start:start+64]\n",
    "\n",
    "        if \"use_dropout\" in model.forward.__code__.co_varnames:\n",
    "            logits = model(batch, use_dropout=False)\n",
    "        else:\n",
    "            logits = model(batch)\n",
    "\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "        for p in probs:\n",
    "            labels = select_k(p)                     \n",
    "            preds.append([str(x) for x in labels]) \n",
    "\n",
    "# SAVE CSV\n",
    "OUT_DIR = Path(\"Submission\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "OUT_PATH = OUT_DIR / \"submission_mlp.csv\"\n",
    "\n",
    "with open(OUT_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"id\", \"label\"])\n",
    "    for pid, labels in zip(test_ids, preds):\n",
    "        w.writerow([pid, \",\".join(labels)])\n",
    "\n",
    "print(f\"üéâ Submission saved ‚Üí {OUT_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
